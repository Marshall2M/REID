+ echo Logging output to exps/example/logs/train_.txt.2017-04-13_17-43-32
Logging output to exps/example/logs/train_.txt.2017-04-13_17-43-32
+ python3 ./tools/train_net.py --gpu 0 --cfg exps/example/config.yml --exp_dir example
/home/mopkobka/CourseWork/venv-gml-nn/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
Called with args:
Namespace(cfg_file='exps/example/config.yml', exp_dir='example', gpu_id=0)
Using config:
{'DATA_DIR': '/home/mopkobka/CourseWork/gml-nn-detector/data',
 'DEDUP_BOXES': 0.0625,
 'DRAW_NET': False,
 'EPS': 1e-14,
 'EXP_DIR': 'example',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODEL': {'ATTACHED_NETS': [{'ANCHOR_RATIOS': [1.0],
                              'ANCHOR_SCALES': [3, 6, 9, 12],
                              'ANCHOR_SHIFT_NUM_XY': [[1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1]],
                              'ARCHITECTURE': "m.add_layer(ConvWithActivation(p('conv1'), "
                                              '128, 3))\n'
                                              "m.add_layer(ConvWithActivation(p('conv2'), "
                                              '128, 3, dropout=0.3),\n'
                                              '            parent_layer=-1)\n'
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_cls'), "
                                              '80, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))\n"
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_box'), "
                                              '80, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))",
                              'BATCHSIZE': 256,
                              'DISABLED': True,
                              'FG_FRACTION': 0.5,
                              'NAME': 'rpn_small',
                              'NEGATIVE_OVERLAP': 0.4,
                              'NMS_THRESH': 0.7,
                              'PARENT_LAYER': 'relu2_2',
                              'POSITIVE_OVERLAP': 0.6,
                              'POST_NMS_TOP_N': 500,
                              'PRE_NMS_TOP_N': 12000,
                              'SQUARE_TARGETS': True,
                              'TOP_NEGATIVE_FRACTION': 0.2,
                              'TYPE': 'RPN'},
                             {'ANCHOR_RATIOS': [1.0],
                              'ANCHOR_SCALES': [2.5,
                                                3.025,
                                                3.66025,
                                                4.4289024999999995,
                                                5.358972025,
                                                6.484356150249999,
                                                7.846070941802498,
                                                9.493745839581022,
                                                11.487432465893036,
                                                13.899793283730574,
                                                16.818749873313998,
                                                20.350687346709933,
                                                24.62433168951902,
                                                29.795441344318014],
                              'ANCHOR_SHIFT_NUM_XY': [[2, 2],
                                                      [2, 2],
                                                      [2, 2],
                                                      [2, 2],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1]],
                              'ARCHITECTURE': "m.add_layer(ConvWithActivation(p('conv1'), "
                                              '512, 3))\n'
                                              "m.add_layer(ConvWithActivation(p('conv2'), "
                                              '512, 3, dropout=0.3),\n'
                                              '            parent_layer=-1)\n'
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_cls'), "
                                              '384, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))\n"
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_box'), "
                                              '384, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))",
                              'BATCHSIZE': 256,
                              'FG_FRACTION': 0.5,
                              'NAME': 'rpn_big',
                              'NEGATIVE_OVERLAP': 0.4,
                              'NMS_THRESH': 0.7,
                              'PARENT_LAYER': 'relu5_3',
                              'POSITIVE_OVERLAP': 0.6,
                              'POST_NMS_TOP_N': 500,
                              'PRE_NMS_TOP_N': 12000,
                              'SQUARE_TARGETS': True,
                              'TOP_NEGATIVE_FRACTION': 0.2,
                              'TYPE': 'RPN'}],
           'NAME': 'faces_example',
           'PRETRAINED_MODEL_CONFIG': '/home/mopkobka/CourseWork/gml-nn-detector/models/vgg16/model.prototxt',
           'WEIGHTS_PATH': '/home/mopkobka/CourseWork/DockerShared/gml-nn/data/NET/VGG16.v2.caffemodel'},
 'MODELS_DIR': '/home/mopkobka/CourseWork/gml-nn-detector/models',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 777,
 'ROOT_DIR': '/home/mopkobka/CourseWork/gml-nn-detector',
 'RPN': {'ANCHOR_BASE_SIZE': 16,
         'ANCHOR_RATIOS': [0.5, 1, 2],
         'ANCHOR_SCALES': [8, 16, 32],
         'ANCHOR_SHIFT_NUM_XY': [(1, 1)]},
 'TEST': {'BBOX_REG': True,
          'DATASETS': [{'MAX_SIZE': 1400,
                        'OUTPUT_FILE': 'videoset.json',
                        'PATH': '/home/local/work/data/faces/BigSampleFNTest_p3lr11/imgs',
                        'SCALES': [350, 1000],
                        'TYPE': 'IMAGES_DIR'},
                       {'MAX_SIZE': 700,
                        'OUTPUT_FILE': 'fddb.json',
                        'PATH': '/home/local/work/data/faces/FDDB/FDDB_p3lr11/imgs',
                        'SCALES': [500],
                        'TYPE': 'IMAGES_DIR'}],
          'DENSE_SCAN': False,
          'FINAL_NMS': 0.5,
          'HAS_RPN': False,
          'MAX_PER_IMAGE': 200,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_ONLY': False,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'VIZUALIZATION': {'DRAW_BOXES': True,
                            'DRAW_SCORES': False,
                            'ENABLE': False,
                            'ONLY_WITH_OBJECTS': False,
                            'SCORE_THRESH': 0.5},
          'WITHOUT_UPSAMPLE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'DATASET': 'default',
           'DATASETS': [{'MAX_SIZE': 700,
                         'PATH': '/home/mopkobka/CourseWork/DockerShared/gml-nn/tiny_dataset',
                         'SCALES': [500],
                         'TYPE': 'BBOX_JSON_MARKING'}],
           'DOUBLE_GENERATE': False,
           'ENABLE_SMART_ORDER': False,
           'GENERATED_FRACTION': 0.0,
           'HAS_RPN': True,
           'PROPOSAL_METHOD': 'selective_search',
           'RATIO_JITTERING': 0.0,
           'REDISTRIBUTE_CLASSES': False,
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_LINEAR_START_TNF': 0.1,
           'RPN_LINEAR_TNF_K': -1.0,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_PERIODIC_TN': 0,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_SQUARE_TARGETS': False,
           'RPN_SQUARE_TARGETS_KY': False,
           'RPN_TOP_NEGATIVE_FRACTION': 0.0,
           'SCALE_JITTERING': 0.0,
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'SOLVER': {'BASE_LR': 0.001,
                      'DISPLAY': {'AVERAGE_LOSS': 100, 'PERIOD': 20},
                      'IMS_PER_BATCH': 2,
                      'LR_POLICY': {'GAMMA': 0.1,
                                    'STEPS': [70000, 120000],
                                    'TYPE': 'multistep'},
                      'MOMENTUM': 0.9,
                      'TRAIN_ITERS': 90000,
                      'WEIGHT_DECAY': 0.0005},
           'SO_FORCE_BATCHSIZE': 500,
           'SO_FORCE_ROUNDS': 8,
           'SO_GOOD_SKIP_PROB': 0.85,
           'SO_TAIL_LEN': 1000,
           'USE_FLIPPED': True,
           'USE_LMDB': False,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True,
 'WEIGHTS_PATH': 'default'}
Output will be saved to `/home/mopkobka/CourseWork/gml-nn-detector/exps/example/output/train_13_04_2017_17_43`
Created solver path: /tmp/tmpx06i90ly
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> /tmp/tmpx06i90ly
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:43:33.697734 10815 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.001
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 0
snapshot_prefix: "faces_example"
net_param {
  name: "GeneratedModel_13_04_2017_17_43"
  layer {
    name: "input"
    type: "Python"
    top: "input_data"
    top: "input_im_info"
    top: "input_gt_boxes"
    top: "input_ignored_boxes"
    python_param {
      module: "layers.roi_data_layer"
      layer: "RoIDataLayer"
      param_str: "{\"num_classes\": 2}"
    }
  }
  layer {
    name: "conv1_1"
    type: "Convolution"
    bottom: "input_data"
    top: "conv1_1"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu1_1"
    type: "ReLU"
    bottom: "conv1_1"
    top: "conv1_1"
  }
  layer {
    name: "conv1_2"
    type: "Convolution"
    bottom: "conv1_1"
    top: "conv1_2"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu1_2"
    type: "ReLU"
    bottom: "conv1_2"
    top: "conv1_2"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1_2"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv2_1"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu2_1"
    type: "ReLU"
    bottom: "conv2_1"
    top: "conv2_1"
  }
  layer {
    name: "conv2_2"
    type: "Convolution"
    bottom: "conv2_1"
    top: "conv2_2"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu2_2"
    type: "ReLU"
    bottom: "conv2_2"
    top: "conv2_2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "conv2_2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv3_1"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_1"
    type: "ReLU"
    bottom: "conv3_1"
    top: "conv3_1"
  }
  layer {
    name: "conv3_2"
    type: "Convolution"
    bottom: "conv3_1"
    top: "conv3_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_2"
    type: "ReLU"
    bottom: "conv3_2"
    top: "conv3_2"
  }
  layer {
    name: "conv3_3"
    type: "Convolution"
    bottom: "conv3_2"
    top: "conv3_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_3"
    type: "ReLU"
    bottom: "conv3_3"
    top: "conv3_3"
  }
  layer {
    name: "pool3"
    type: "Pooling"
    bottom: "conv3_3"
    top: "pool3"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv4_1"
    type: "Convolution"
    bottom: "pool3"
    top: "conv4_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_1"
    type: "ReLU"
    bottom: "conv4_1"
    top: "conv4_1"
  }
  layer {
    name: "conv4_2"
    type: "Convolution"
    bottom: "conv4_1"
    top: "conv4_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_2"
    type: "ReLU"
    bottom: "conv4_2"
    top: "conv4_2"
  }
  layer {
    name: "conv4_3"
    type: "Convolution"
    bottom: "conv4_2"
    top: "conv4_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_3"
    type: "ReLU"
    bottom: "conv4_3"
    top: "conv4_3"
  }
  layer {
    name: "pool4"
    type: "Pooling"
    bottom: "conv4_3"
    top: "pool4"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv5_1"
    type: "Convolution"
    bottom: "pool4"
    top: "conv5_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_1"
    type: "ReLU"
    bottom: "conv5_1"
    top: "conv5_1"
  }
  layer {
    name: "conv5_2"
    type: "Convolution"
    bottom: "conv5_1"
    top: "conv5_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_2"
    type: "ReLU"
    bottom: "conv5_2"
    top: "conv5_2"
  }
  layer {
    name: "conv5_3"
    type: "Convolution"
    bottom: "conv5_2"
    top: "conv5_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_3"
    type: "ReLU"
    bottom: "conv5_3"
    top: "conv5_3"
  }
  layer {
    name: "rpn_big_conv1"
    type: "Convolution"
    bottom: "conv5_3"
    top: "rpn_big_conv1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_conv1_relu"
    type: "ReLU"
    bottom: "rpn_big_conv1"
    top: "rpn_big_conv1"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_conv2"
    type: "Convolution"
    bottom: "rpn_big_conv1"
    top: "rpn_big_conv2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_conv2_relu"
    type: "ReLU"
    bottom: "rpn_big_conv2"
    top: "rpn_big_conv2"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_conv2_drop"
    type: "Dropout"
    bottom: "rpn_big_conv2"
    top: "rpn_big_conv2"
    dropout_param {
      dropout_ratio: 0.3
    }
  }
  layer {
    name: "rpn_big_output_cls"
    type: "Convolution"
    bottom: "rpn_big_conv2"
    top: "rpn_big_output_cls"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_output_cls_relu"
    type: "ReLU"
    bottom: "rpn_big_output_cls"
    top: "rpn_big_output_cls"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_cls_score"
    type: "Convolution"
    bottom: "rpn_big_output_cls"
    top: "rpn_big_cls_score"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 52
      pad: 0
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_cls_score_reshape"
    type: "Reshape"
    bottom: "rpn_big_cls_score"
    top: "rpn_big_cls_score_reshape"
    reshape_param {
      shape {
        dim: 0
        dim: 2
        dim: -1
        dim: 0
      }
    }
  }
  layer {
    name: "rpn_big_cls_prob"
    type: "Softmax"
    bottom: "rpn_big_cls_score_reshape"
    top: "rpn_big_cls_prob"
  }
  layer {
    name: "rpn_big_cls_prob_reshape"
    type: "Reshape"
    bottom: "rpn_big_cls_prob"
    top: "rpn_big_cls_prob_reshape"
    reshape_param {
      shape {
        dim: 0
        dim: 52
        dim: -1
        dim: 0
      }
    }
  }
  layer {
    name: "rpn_big_anchor_target"
    type: "Python"
    bottom: "rpn_big_cls_score"
    bottom: "input_gt_boxes"
    bottom: "input_ignored_boxes"
    bottom: "input_im_info"
    bottom: "input_data"
    bottom: "rpn_big_cls_prob_reshape"
    top: "rpn_big_anchor_target_labels"
    top: "rpn_big_anchor_target_bbox_targets"
    top: "rpn_big_anchor_target_inside_weights"
    top: "rpn_big_anchor_target_outside_weights"
    python_param {
      module: "rpn.anchor_target_layer"
      layer: "AnchorTargetLayer"
      param_str: "{\"batchsize\": 256, \"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"square_targets\": true, \"negative_overlap\": 0.4, \"anchor_ratios\": [1.0], \"num_classes\": 1, \"fg_fraction\": 0.5, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"name\": \"rpn_big\", \"feat_stride\": 16, \"positive_overlap\": 0.6, \"tn_fraction\": 0.2}"
    }
  }
  layer {
    name: "rpn_big_loss_cls"
    type: "SoftmaxWithLoss"
    bottom: "rpn_big_cls_score_reshape"
    bottom: "rpn_big_anchor_target_labels"
    top: "rpn_big_loss_cls"
    loss_weight: 1
    propagate_down: true
    propagate_down: false
    loss_param {
      ignore_label: -1
      normalization: VALID
    }
  }
  layer {
    name: "rpn_big_output_box"
    type: "Convolution"
    bottom: "rpn_big_conv2"
    top: "rpn_big_output_box"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_output_box_relu"
    type: "ReLU"
    bottom: "rpn_big_output_box"
    top: "rpn_big_output_box"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_bbox_pred"
    type: "Convolution"
    bottom: "rpn_big_output_box"
    top: "rpn_big_bbox_pred"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 104
      pad: 0
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_loss_bbox"
    type: "Python"
    bottom: "rpn_big_bbox_pred"
    bottom: "rpn_big_anchor_target_bbox_targets"
    bottom: "rpn_big_anchor_target_inside_weights"
    bottom: "rpn_big_anchor_target_outside_weights"
    top: "rpn_big_loss_bbox"
    loss_weight: 1
    python_param {
      module: "layers.smooth_l1_loss"
      layer: "SmoothL1LossLayer"
      param_str: "{\"sigma\": 3}"
    }
  }
  layer {
    name: "proposal"
    type: "Python"
    bottom: "rpn_big_cls_prob_reshape"
    bottom: "rpn_big_bbox_pred"
    bottom: "input_im_info"
    top: "rpn_rois"
    python_param {
      module: "rpn.proposal_layer"
      layer: "ProposalLayer"
      param_str: "{\"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"feat_stride\": 16, \"num_classes\": 1, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"square_targets\": true, \"name\": \"rpn_big\", \"batchsize\": 256, \"anchor_ratios\": [1.0]}"
    }
  }
  layer {
    name: "roi-data"
    type: "Python"
    bottom: "rpn_rois"
    bottom: "input_gt_boxes"
    top: "rois"
    top: "labels"
    top: "bbox_targets"
    top: "bbox_inside_weights"
    top: "bbox_outside_weights"
    top: "pid_label"
    python_param {
      module: "rpn.proposal_target_layer"
      layer: "ProposalTargetLayer"
      param_str: "{\"num_classes\": 2, \"bg_aux_label\": 5532}"
    }
  }
}
average_loss: 100
stepvalue: 70000
stepvalue: 120000
iter_size: 2
I0413 17:43:33.699112 10815 solver.cpp:86] Creating training net specified in net_param.
I0413 17:43:33.699759 10815 net.cpp:58] Initializing net from parameters: 
name: "GeneratedModel_13_04_2017_17_43"
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Python"
  top: "input_data"
  top: "input_im_info"
  top: "input_gt_boxes"
  top: "input_ignored_boxes"
  python_param {
    module: "layers.roi_data_layer"
    layer: "RoIDataLayer"
    param_str: "{\"num_classes\": 2}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "input_data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_big_conv1"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn_big_conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_conv1_relu"
  type: "ReLU"
  bottom: "rpn_big_conv1"
  top: "rpn_big_conv1"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_conv2"
  type: "Convolution"
  bottom: "rpn_big_conv1"
  top: "rpn_big_conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_conv2_relu"
  type: "ReLU"
  bottom: "rpn_big_conv2"
  top: "rpn_big_conv2"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_conv2_drop"
  type: "Dropout"
  bottom: "rpn_big_conv2"
  top: "rpn_big_conv2"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "rpn_big_output_cls"
  type: "Convolution"
  bottom: "rpn_big_conv2"
  top: "rpn_big_output_cls"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_output_cls_relu"
  type: "ReLU"
  bottom: "rpn_big_output_cls"
  top: "rpn_big_output_cls"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_cls_score"
  type: "Convolution"
  bottom: "rpn_big_output_cls"
  top: "rpn_big_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 52
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_big_cls_score"
  top: "rpn_big_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_big_cls_prob"
  type: "Softmax"
  bottom: "rpn_big_cls_score_reshape"
  top: "rpn_big_cls_prob"
}
layer {
  name: "rpn_big_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_big_cls_prob"
  top: "rpn_big_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 52
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_big_anchor_target"
  type: "Python"
  bottom: "rpn_big_cls_score"
  bottom: "input_gt_boxes"
  bottom: "input_ignored_boxes"
  bottom: "input_im_info"
  bottom: "input_data"
  bottom: "rpn_big_cls_prob_reshape"
  top: "rpn_big_anchor_target_labels"
  top: "rpn_big_anchor_target_bbox_targets"
  top: "rpn_big_anchor_target_inside_weights"
  top: "rpn_big_anchor_target_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "{\"batchsize\": 256, \"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"square_targets\": true, \"negative_overlap\": 0.4, \"anchor_ratios\": [1.0], \"num_classes\": 1, \"fg_fraction\": 0.5, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"name\": \"rpn_big\", \"feat_stride\": 16, \"positive_overlap\": 0.6, \"tn_fraction\": 0.2}"
  }
}
layer {
  name: "rpn_big_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_big_cls_score_reshape"
  bottom: "rpn_big_anchor_target_labels"
  top: "rpn_big_loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalization: VALID
  }
}
layer {
  name: "rpn_big_output_box"
  type: "Convolution"
  bottom: "rpn_big_conv2"
  top: "rpn_big_output_box"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_output_box_relu"
  type: "ReLU"
  bottom: "rpn_big_output_box"
  top: "rpn_big_output_box"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_bbox_pred"
  type: "Convolution"
  bottom: "rpn_big_output_box"
  top: "rpn_big_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 104
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_loss_bbox"
  type: "Python"
  bottom: "rpn_big_bbox_pred"
  bottom: "rpn_big_anchor_target_bbox_targets"
  bottom: "rpn_big_anchor_target_inside_weights"
  bottom: "rpn_big_anchor_target_outside_weights"
  top: "rpn_big_loss_bbox"
  loss_weight: 1
  python_param {
    module: "layers.smooth_l1_loss"
    layer: "SmoothL1LossLayer"
    param_str: "{\"sigma\": 3}"
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_big_cls_prob_reshape"
  bottom: "rpn_big_bbox_pred"
  bottom: "input_im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "{\"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"feat_stride\": 16, \"num_classes\": 1, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"square_targets\": true, \"name\": \"rpn_big\", \"batchsize\": 256, \"anchor_ratios\": [1.0]}"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "input_gt_boxes"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "pid_label"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "{\"num_classes\": 2, \"bg_aux_label\": 5532}"
  }
}
I0413 17:43:33.700078 10815 layer_factory.hpp:77] Creating layer input
I0413 17:43:33.701937 10815 net.cpp:100] Creating Layer input
I0413 17:43:33.701961 10815 net.cpp:408] input -> input_data
I0413 17:43:33.701977 10815 net.cpp:408] input -> input_im_info
I0413 17:43:33.701988 10815 net.cpp:408] input -> input_gt_boxes
I0413 17:43:33.702002 10815 net.cpp:408] input -> input_ignored_boxes
RoiDataLayer: name_to_top: {'data': 0, 'im_info': 1, 'gt_boxes': 2, 'ignored_boxes': 3}
I0413 17:43:34.021268 10815 net.cpp:150] Setting up input
I0413 17:43:34.021299 10815 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 17:43:34.021307 10815 net.cpp:157] Top shape: 1 3 (3)
I0413 17:43:34.021316 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.021322 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.021340 10815 net.cpp:165] Memory required for data: 18000052
I0413 17:43:34.021350 10815 layer_factory.hpp:77] Creating layer input_data_input_0_split
I0413 17:43:34.021369 10815 net.cpp:100] Creating Layer input_data_input_0_split
I0413 17:43:34.021378 10815 net.cpp:434] input_data_input_0_split <- input_data
I0413 17:43:34.021389 10815 net.cpp:408] input_data_input_0_split -> input_data_input_0_split_0
I0413 17:43:34.021406 10815 net.cpp:408] input_data_input_0_split -> input_data_input_0_split_1
I0413 17:43:34.021456 10815 net.cpp:150] Setting up input_data_input_0_split
I0413 17:43:34.021468 10815 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 17:43:34.021476 10815 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 17:43:34.021481 10815 net.cpp:165] Memory required for data: 54000052
I0413 17:43:34.021486 10815 layer_factory.hpp:77] Creating layer input_im_info_input_1_split
I0413 17:43:34.021495 10815 net.cpp:100] Creating Layer input_im_info_input_1_split
I0413 17:43:34.021505 10815 net.cpp:434] input_im_info_input_1_split <- input_im_info
I0413 17:43:34.021513 10815 net.cpp:408] input_im_info_input_1_split -> input_im_info_input_1_split_0
I0413 17:43:34.021524 10815 net.cpp:408] input_im_info_input_1_split -> input_im_info_input_1_split_1
I0413 17:43:34.021565 10815 net.cpp:150] Setting up input_im_info_input_1_split
I0413 17:43:34.021579 10815 net.cpp:157] Top shape: 1 3 (3)
I0413 17:43:34.021586 10815 net.cpp:157] Top shape: 1 3 (3)
I0413 17:43:34.021591 10815 net.cpp:165] Memory required for data: 54000076
I0413 17:43:34.021598 10815 layer_factory.hpp:77] Creating layer input_gt_boxes_input_2_split
I0413 17:43:34.021607 10815 net.cpp:100] Creating Layer input_gt_boxes_input_2_split
I0413 17:43:34.021613 10815 net.cpp:434] input_gt_boxes_input_2_split <- input_gt_boxes
I0413 17:43:34.021622 10815 net.cpp:408] input_gt_boxes_input_2_split -> input_gt_boxes_input_2_split_0
I0413 17:43:34.021634 10815 net.cpp:408] input_gt_boxes_input_2_split -> input_gt_boxes_input_2_split_1
I0413 17:43:34.021677 10815 net.cpp:150] Setting up input_gt_boxes_input_2_split
I0413 17:43:34.021687 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.021695 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.021700 10815 net.cpp:165] Memory required for data: 54000116
I0413 17:43:34.021705 10815 layer_factory.hpp:77] Creating layer conv1_1
I0413 17:43:34.021720 10815 net.cpp:100] Creating Layer conv1_1
I0413 17:43:34.021728 10815 net.cpp:434] conv1_1 <- input_data_input_0_split_0
I0413 17:43:34.021736 10815 net.cpp:408] conv1_1 -> conv1_1
I0413 17:43:34.025157 10815 net.cpp:150] Setting up conv1_1
I0413 17:43:34.025194 10815 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 17:43:34.025198 10815 net.cpp:165] Memory required for data: 438000116
I0413 17:43:34.025221 10815 layer_factory.hpp:77] Creating layer relu1_1
I0413 17:43:34.025238 10815 net.cpp:100] Creating Layer relu1_1
I0413 17:43:34.025246 10815 net.cpp:434] relu1_1 <- conv1_1
I0413 17:43:34.025256 10815 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0413 17:43:34.025272 10815 net.cpp:150] Setting up relu1_1
I0413 17:43:34.025281 10815 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 17:43:34.025287 10815 net.cpp:165] Memory required for data: 822000116
I0413 17:43:34.025293 10815 layer_factory.hpp:77] Creating layer conv1_2
I0413 17:43:34.025306 10815 net.cpp:100] Creating Layer conv1_2
I0413 17:43:34.025313 10815 net.cpp:434] conv1_2 <- conv1_1
I0413 17:43:34.025323 10815 net.cpp:408] conv1_2 -> conv1_2
I0413 17:43:34.028575 10815 net.cpp:150] Setting up conv1_2
I0413 17:43:34.028612 10815 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 17:43:34.028616 10815 net.cpp:165] Memory required for data: 1206000116
I0413 17:43:34.028638 10815 layer_factory.hpp:77] Creating layer relu1_2
I0413 17:43:34.028656 10815 net.cpp:100] Creating Layer relu1_2
I0413 17:43:34.028663 10815 net.cpp:434] relu1_2 <- conv1_2
I0413 17:43:34.028676 10815 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0413 17:43:34.028692 10815 net.cpp:150] Setting up relu1_2
I0413 17:43:34.028700 10815 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 17:43:34.028707 10815 net.cpp:165] Memory required for data: 1590000116
I0413 17:43:34.028712 10815 layer_factory.hpp:77] Creating layer pool1
I0413 17:43:34.028725 10815 net.cpp:100] Creating Layer pool1
I0413 17:43:34.028731 10815 net.cpp:434] pool1 <- conv1_2
I0413 17:43:34.028741 10815 net.cpp:408] pool1 -> pool1
I0413 17:43:34.028831 10815 net.cpp:150] Setting up pool1
I0413 17:43:34.028841 10815 net.cpp:157] Top shape: 1 64 500 750 (24000000)
I0413 17:43:34.028847 10815 net.cpp:165] Memory required for data: 1686000116
I0413 17:43:34.028853 10815 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:43:34.028868 10815 net.cpp:100] Creating Layer conv2_1
I0413 17:43:34.028875 10815 net.cpp:434] conv2_1 <- pool1
I0413 17:43:34.028887 10815 net.cpp:408] conv2_1 -> conv2_1
I0413 17:43:34.030244 10815 net.cpp:150] Setting up conv2_1
I0413 17:43:34.030273 10815 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 17:43:34.030277 10815 net.cpp:165] Memory required for data: 1878000116
I0413 17:43:34.030290 10815 layer_factory.hpp:77] Creating layer relu2_1
I0413 17:43:34.030298 10815 net.cpp:100] Creating Layer relu2_1
I0413 17:43:34.030306 10815 net.cpp:434] relu2_1 <- conv2_1
I0413 17:43:34.030313 10815 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0413 17:43:34.030324 10815 net.cpp:150] Setting up relu2_1
I0413 17:43:34.030330 10815 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 17:43:34.030333 10815 net.cpp:165] Memory required for data: 2070000116
I0413 17:43:34.030336 10815 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:43:34.030344 10815 net.cpp:100] Creating Layer conv2_2
I0413 17:43:34.030349 10815 net.cpp:434] conv2_2 <- conv2_1
I0413 17:43:34.030355 10815 net.cpp:408] conv2_2 -> conv2_2
I0413 17:43:34.031296 10815 net.cpp:150] Setting up conv2_2
I0413 17:43:34.031323 10815 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 17:43:34.031327 10815 net.cpp:165] Memory required for data: 2262000116
I0413 17:43:34.031337 10815 layer_factory.hpp:77] Creating layer relu2_2
I0413 17:43:34.031347 10815 net.cpp:100] Creating Layer relu2_2
I0413 17:43:34.031352 10815 net.cpp:434] relu2_2 <- conv2_2
I0413 17:43:34.031359 10815 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0413 17:43:34.031369 10815 net.cpp:150] Setting up relu2_2
I0413 17:43:34.031376 10815 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 17:43:34.031379 10815 net.cpp:165] Memory required for data: 2454000116
I0413 17:43:34.031383 10815 layer_factory.hpp:77] Creating layer pool2
I0413 17:43:34.031388 10815 net.cpp:100] Creating Layer pool2
I0413 17:43:34.031391 10815 net.cpp:434] pool2 <- conv2_2
I0413 17:43:34.031396 10815 net.cpp:408] pool2 -> pool2
I0413 17:43:34.031440 10815 net.cpp:150] Setting up pool2
I0413 17:43:34.031447 10815 net.cpp:157] Top shape: 1 128 250 375 (12000000)
I0413 17:43:34.031450 10815 net.cpp:165] Memory required for data: 2502000116
I0413 17:43:34.031453 10815 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:43:34.031462 10815 net.cpp:100] Creating Layer conv3_1
I0413 17:43:34.031467 10815 net.cpp:434] conv3_1 <- pool2
I0413 17:43:34.031474 10815 net.cpp:408] conv3_1 -> conv3_1
I0413 17:43:34.032547 10815 net.cpp:150] Setting up conv3_1
I0413 17:43:34.032572 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.032577 10815 net.cpp:165] Memory required for data: 2598000116
I0413 17:43:34.032590 10815 layer_factory.hpp:77] Creating layer relu3_1
I0413 17:43:34.032600 10815 net.cpp:100] Creating Layer relu3_1
I0413 17:43:34.032605 10815 net.cpp:434] relu3_1 <- conv3_1
I0413 17:43:34.032613 10815 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0413 17:43:34.032624 10815 net.cpp:150] Setting up relu3_1
I0413 17:43:34.032627 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.032630 10815 net.cpp:165] Memory required for data: 2694000116
I0413 17:43:34.032634 10815 layer_factory.hpp:77] Creating layer conv3_2
I0413 17:43:34.032646 10815 net.cpp:100] Creating Layer conv3_2
I0413 17:43:34.032650 10815 net.cpp:434] conv3_2 <- conv3_1
I0413 17:43:34.032656 10815 net.cpp:408] conv3_2 -> conv3_2
I0413 17:43:34.033895 10815 net.cpp:150] Setting up conv3_2
I0413 17:43:34.033923 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.033927 10815 net.cpp:165] Memory required for data: 2790000116
I0413 17:43:34.033936 10815 layer_factory.hpp:77] Creating layer relu3_2
I0413 17:43:34.033946 10815 net.cpp:100] Creating Layer relu3_2
I0413 17:43:34.033951 10815 net.cpp:434] relu3_2 <- conv3_2
I0413 17:43:34.033959 10815 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0413 17:43:34.033969 10815 net.cpp:150] Setting up relu3_2
I0413 17:43:34.033974 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.033977 10815 net.cpp:165] Memory required for data: 2886000116
I0413 17:43:34.033980 10815 layer_factory.hpp:77] Creating layer conv3_3
I0413 17:43:34.033988 10815 net.cpp:100] Creating Layer conv3_3
I0413 17:43:34.033993 10815 net.cpp:434] conv3_3 <- conv3_2
I0413 17:43:34.033998 10815 net.cpp:408] conv3_3 -> conv3_3
I0413 17:43:34.035552 10815 net.cpp:150] Setting up conv3_3
I0413 17:43:34.035583 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.035586 10815 net.cpp:165] Memory required for data: 2982000116
I0413 17:43:34.035596 10815 layer_factory.hpp:77] Creating layer relu3_3
I0413 17:43:34.035606 10815 net.cpp:100] Creating Layer relu3_3
I0413 17:43:34.035611 10815 net.cpp:434] relu3_3 <- conv3_3
I0413 17:43:34.035619 10815 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0413 17:43:34.035630 10815 net.cpp:150] Setting up relu3_3
I0413 17:43:34.035636 10815 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 17:43:34.035640 10815 net.cpp:165] Memory required for data: 3078000116
I0413 17:43:34.035642 10815 layer_factory.hpp:77] Creating layer pool3
I0413 17:43:34.035648 10815 net.cpp:100] Creating Layer pool3
I0413 17:43:34.035651 10815 net.cpp:434] pool3 <- conv3_3
I0413 17:43:34.035656 10815 net.cpp:408] pool3 -> pool3
I0413 17:43:34.035701 10815 net.cpp:150] Setting up pool3
I0413 17:43:34.035707 10815 net.cpp:157] Top shape: 1 256 125 188 (6016000)
I0413 17:43:34.035711 10815 net.cpp:165] Memory required for data: 3102064116
I0413 17:43:34.035714 10815 layer_factory.hpp:77] Creating layer conv4_1
I0413 17:43:34.035723 10815 net.cpp:100] Creating Layer conv4_1
I0413 17:43:34.035727 10815 net.cpp:434] conv4_1 <- pool3
I0413 17:43:34.035734 10815 net.cpp:408] conv4_1 -> conv4_1
I0413 17:43:34.038885 10815 net.cpp:150] Setting up conv4_1
I0413 17:43:34.038925 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.038930 10815 net.cpp:165] Memory required for data: 3150192116
I0413 17:43:34.038945 10815 layer_factory.hpp:77] Creating layer relu4_1
I0413 17:43:34.038959 10815 net.cpp:100] Creating Layer relu4_1
I0413 17:43:34.038967 10815 net.cpp:434] relu4_1 <- conv4_1
I0413 17:43:34.038978 10815 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0413 17:43:34.038992 10815 net.cpp:150] Setting up relu4_1
I0413 17:43:34.039001 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.039006 10815 net.cpp:165] Memory required for data: 3198320116
I0413 17:43:34.039012 10815 layer_factory.hpp:77] Creating layer conv4_2
I0413 17:43:34.039026 10815 net.cpp:100] Creating Layer conv4_2
I0413 17:43:34.039032 10815 net.cpp:434] conv4_2 <- conv4_1
I0413 17:43:34.039041 10815 net.cpp:408] conv4_2 -> conv4_2
I0413 17:43:34.043524 10815 net.cpp:150] Setting up conv4_2
I0413 17:43:34.043560 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.043563 10815 net.cpp:165] Memory required for data: 3246448116
I0413 17:43:34.043583 10815 layer_factory.hpp:77] Creating layer relu4_2
I0413 17:43:34.043598 10815 net.cpp:100] Creating Layer relu4_2
I0413 17:43:34.043607 10815 net.cpp:434] relu4_2 <- conv4_2
I0413 17:43:34.043617 10815 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0413 17:43:34.043632 10815 net.cpp:150] Setting up relu4_2
I0413 17:43:34.043642 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.043648 10815 net.cpp:165] Memory required for data: 3294576116
I0413 17:43:34.043653 10815 layer_factory.hpp:77] Creating layer conv4_3
I0413 17:43:34.043666 10815 net.cpp:100] Creating Layer conv4_3
I0413 17:43:34.043673 10815 net.cpp:434] conv4_3 <- conv4_2
I0413 17:43:34.043684 10815 net.cpp:408] conv4_3 -> conv4_3
I0413 17:43:34.048035 10815 net.cpp:150] Setting up conv4_3
I0413 17:43:34.048070 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.048074 10815 net.cpp:165] Memory required for data: 3342704116
I0413 17:43:34.048084 10815 layer_factory.hpp:77] Creating layer relu4_3
I0413 17:43:34.048099 10815 net.cpp:100] Creating Layer relu4_3
I0413 17:43:34.048106 10815 net.cpp:434] relu4_3 <- conv4_3
I0413 17:43:34.048122 10815 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0413 17:43:34.048137 10815 net.cpp:150] Setting up relu4_3
I0413 17:43:34.048147 10815 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 17:43:34.048153 10815 net.cpp:165] Memory required for data: 3390832116
I0413 17:43:34.048158 10815 layer_factory.hpp:77] Creating layer pool4
I0413 17:43:34.048167 10815 net.cpp:100] Creating Layer pool4
I0413 17:43:34.048174 10815 net.cpp:434] pool4 <- conv4_3
I0413 17:43:34.048184 10815 net.cpp:408] pool4 -> pool4
I0413 17:43:34.048234 10815 net.cpp:150] Setting up pool4
I0413 17:43:34.048249 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.048254 10815 net.cpp:165] Memory required for data: 3402960372
I0413 17:43:34.048259 10815 layer_factory.hpp:77] Creating layer conv5_1
I0413 17:43:34.048271 10815 net.cpp:100] Creating Layer conv5_1
I0413 17:43:34.048279 10815 net.cpp:434] conv5_1 <- pool4
I0413 17:43:34.048292 10815 net.cpp:408] conv5_1 -> conv5_1
I0413 17:43:34.053113 10815 net.cpp:150] Setting up conv5_1
I0413 17:43:34.053143 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.053148 10815 net.cpp:165] Memory required for data: 3415088628
I0413 17:43:34.053158 10815 layer_factory.hpp:77] Creating layer relu5_1
I0413 17:43:34.053172 10815 net.cpp:100] Creating Layer relu5_1
I0413 17:43:34.053180 10815 net.cpp:434] relu5_1 <- conv5_1
I0413 17:43:34.053194 10815 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0413 17:43:34.053207 10815 net.cpp:150] Setting up relu5_1
I0413 17:43:34.053215 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.053220 10815 net.cpp:165] Memory required for data: 3427216884
I0413 17:43:34.053225 10815 layer_factory.hpp:77] Creating layer conv5_2
I0413 17:43:34.053238 10815 net.cpp:100] Creating Layer conv5_2
I0413 17:43:34.053244 10815 net.cpp:434] conv5_2 <- conv5_1
I0413 17:43:34.053256 10815 net.cpp:408] conv5_2 -> conv5_2
I0413 17:43:34.057634 10815 net.cpp:150] Setting up conv5_2
I0413 17:43:34.057667 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.057670 10815 net.cpp:165] Memory required for data: 3439345140
I0413 17:43:34.057682 10815 layer_factory.hpp:77] Creating layer relu5_2
I0413 17:43:34.057696 10815 net.cpp:100] Creating Layer relu5_2
I0413 17:43:34.057703 10815 net.cpp:434] relu5_2 <- conv5_2
I0413 17:43:34.057718 10815 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0413 17:43:34.057732 10815 net.cpp:150] Setting up relu5_2
I0413 17:43:34.057740 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.057745 10815 net.cpp:165] Memory required for data: 3451473396
I0413 17:43:34.057750 10815 layer_factory.hpp:77] Creating layer conv5_3
I0413 17:43:34.057773 10815 net.cpp:100] Creating Layer conv5_3
I0413 17:43:34.057785 10815 net.cpp:434] conv5_3 <- conv5_2
I0413 17:43:34.057796 10815 net.cpp:408] conv5_3 -> conv5_3
I0413 17:43:34.062479 10815 net.cpp:150] Setting up conv5_3
I0413 17:43:34.062516 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.062520 10815 net.cpp:165] Memory required for data: 3463601652
I0413 17:43:34.062530 10815 layer_factory.hpp:77] Creating layer relu5_3
I0413 17:43:34.062542 10815 net.cpp:100] Creating Layer relu5_3
I0413 17:43:34.062549 10815 net.cpp:434] relu5_3 <- conv5_3
I0413 17:43:34.062563 10815 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0413 17:43:34.062578 10815 net.cpp:150] Setting up relu5_3
I0413 17:43:34.062589 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.062594 10815 net.cpp:165] Memory required for data: 3475729908
I0413 17:43:34.062615 10815 layer_factory.hpp:77] Creating layer rpn_big_conv1
I0413 17:43:34.062640 10815 net.cpp:100] Creating Layer rpn_big_conv1
I0413 17:43:34.062649 10815 net.cpp:434] rpn_big_conv1 <- conv5_3
I0413 17:43:34.062660 10815 net.cpp:408] rpn_big_conv1 -> rpn_big_conv1
I0413 17:43:34.087905 10815 net.cpp:150] Setting up rpn_big_conv1
I0413 17:43:34.087935 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.087939 10815 net.cpp:165] Memory required for data: 3487858164
I0413 17:43:34.087949 10815 layer_factory.hpp:77] Creating layer rpn_big_conv1_relu
I0413 17:43:34.087960 10815 net.cpp:100] Creating Layer rpn_big_conv1_relu
I0413 17:43:34.087966 10815 net.cpp:434] rpn_big_conv1_relu <- rpn_big_conv1
I0413 17:43:34.087976 10815 net.cpp:395] rpn_big_conv1_relu -> rpn_big_conv1 (in-place)
I0413 17:43:34.087990 10815 net.cpp:150] Setting up rpn_big_conv1_relu
I0413 17:43:34.087998 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.088003 10815 net.cpp:165] Memory required for data: 3499986420
I0413 17:43:34.088009 10815 layer_factory.hpp:77] Creating layer rpn_big_conv2
I0413 17:43:34.088032 10815 net.cpp:100] Creating Layer rpn_big_conv2
I0413 17:43:34.088039 10815 net.cpp:434] rpn_big_conv2 <- rpn_big_conv1
I0413 17:43:34.088049 10815 net.cpp:408] rpn_big_conv2 -> rpn_big_conv2
I0413 17:43:34.113167 10815 net.cpp:150] Setting up rpn_big_conv2
I0413 17:43:34.113198 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.113203 10815 net.cpp:165] Memory required for data: 3512114676
I0413 17:43:34.113212 10815 layer_factory.hpp:77] Creating layer rpn_big_conv2_relu
I0413 17:43:34.113225 10815 net.cpp:100] Creating Layer rpn_big_conv2_relu
I0413 17:43:34.113240 10815 net.cpp:434] rpn_big_conv2_relu <- rpn_big_conv2
I0413 17:43:34.113250 10815 net.cpp:395] rpn_big_conv2_relu -> rpn_big_conv2 (in-place)
I0413 17:43:34.113266 10815 net.cpp:150] Setting up rpn_big_conv2_relu
I0413 17:43:34.113283 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.113288 10815 net.cpp:165] Memory required for data: 3524242932
I0413 17:43:34.113293 10815 layer_factory.hpp:77] Creating layer rpn_big_conv2_drop
I0413 17:43:34.113303 10815 net.cpp:100] Creating Layer rpn_big_conv2_drop
I0413 17:43:34.113310 10815 net.cpp:434] rpn_big_conv2_drop <- rpn_big_conv2
I0413 17:43:34.113318 10815 net.cpp:395] rpn_big_conv2_drop -> rpn_big_conv2 (in-place)
I0413 17:43:34.113361 10815 net.cpp:150] Setting up rpn_big_conv2_drop
I0413 17:43:34.113373 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.113379 10815 net.cpp:165] Memory required for data: 3536371188
I0413 17:43:34.113386 10815 layer_factory.hpp:77] Creating layer rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 17:43:34.113404 10815 net.cpp:100] Creating Layer rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 17:43:34.113411 10815 net.cpp:434] rpn_big_conv2_rpn_big_conv2_drop_0_split <- rpn_big_conv2
I0413 17:43:34.113421 10815 net.cpp:408] rpn_big_conv2_rpn_big_conv2_drop_0_split -> rpn_big_conv2_rpn_big_conv2_drop_0_split_0
I0413 17:43:34.113433 10815 net.cpp:408] rpn_big_conv2_rpn_big_conv2_drop_0_split -> rpn_big_conv2_rpn_big_conv2_drop_0_split_1
I0413 17:43:34.113482 10815 net.cpp:150] Setting up rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 17:43:34.113493 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.113502 10815 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 17:43:34.113507 10815 net.cpp:165] Memory required for data: 3560627700
I0413 17:43:34.113512 10815 layer_factory.hpp:77] Creating layer rpn_big_output_cls
I0413 17:43:34.113528 10815 net.cpp:100] Creating Layer rpn_big_output_cls
I0413 17:43:34.113535 10815 net.cpp:434] rpn_big_output_cls <- rpn_big_conv2_rpn_big_conv2_drop_0_split_0
I0413 17:43:34.113548 10815 net.cpp:408] rpn_big_output_cls -> rpn_big_output_cls
I0413 17:43:34.132701 10815 net.cpp:150] Setting up rpn_big_output_cls
I0413 17:43:34.132733 10815 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 17:43:34.132737 10815 net.cpp:165] Memory required for data: 3569723892
I0413 17:43:34.132748 10815 layer_factory.hpp:77] Creating layer rpn_big_output_cls_relu
I0413 17:43:34.132764 10815 net.cpp:100] Creating Layer rpn_big_output_cls_relu
I0413 17:43:34.132772 10815 net.cpp:434] rpn_big_output_cls_relu <- rpn_big_output_cls
I0413 17:43:34.132783 10815 net.cpp:395] rpn_big_output_cls_relu -> rpn_big_output_cls (in-place)
I0413 17:43:34.132797 10815 net.cpp:150] Setting up rpn_big_output_cls_relu
I0413 17:43:34.132804 10815 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 17:43:34.132809 10815 net.cpp:165] Memory required for data: 3578820084
I0413 17:43:34.132814 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_score
I0413 17:43:34.132832 10815 net.cpp:100] Creating Layer rpn_big_cls_score
I0413 17:43:34.132838 10815 net.cpp:434] rpn_big_cls_score <- rpn_big_output_cls
I0413 17:43:34.132849 10815 net.cpp:408] rpn_big_cls_score -> rpn_big_cls_score
I0413 17:43:34.135330 10815 net.cpp:150] Setting up rpn_big_cls_score
I0413 17:43:34.135349 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135354 10815 net.cpp:165] Memory required for data: 3579987380
I0413 17:43:34.135372 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 17:43:34.135385 10815 net.cpp:100] Creating Layer rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 17:43:34.135391 10815 net.cpp:434] rpn_big_cls_score_rpn_big_cls_score_0_split <- rpn_big_cls_score
I0413 17:43:34.135403 10815 net.cpp:408] rpn_big_cls_score_rpn_big_cls_score_0_split -> rpn_big_cls_score_rpn_big_cls_score_0_split_0
I0413 17:43:34.135417 10815 net.cpp:408] rpn_big_cls_score_rpn_big_cls_score_0_split -> rpn_big_cls_score_rpn_big_cls_score_0_split_1
I0413 17:43:34.135466 10815 net.cpp:150] Setting up rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 17:43:34.135478 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135485 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135490 10815 net.cpp:165] Memory required for data: 3582321972
I0413 17:43:34.135495 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_score_reshape
I0413 17:43:34.135509 10815 net.cpp:100] Creating Layer rpn_big_cls_score_reshape
I0413 17:43:34.135514 10815 net.cpp:434] rpn_big_cls_score_reshape <- rpn_big_cls_score_rpn_big_cls_score_0_split_0
I0413 17:43:34.135524 10815 net.cpp:408] rpn_big_cls_score_reshape -> rpn_big_cls_score_reshape
I0413 17:43:34.135557 10815 net.cpp:150] Setting up rpn_big_cls_score_reshape
I0413 17:43:34.135568 10815 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 17:43:34.135573 10815 net.cpp:165] Memory required for data: 3583489268
I0413 17:43:34.135578 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 17:43:34.135588 10815 net.cpp:100] Creating Layer rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 17:43:34.135594 10815 net.cpp:434] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split <- rpn_big_cls_score_reshape
I0413 17:43:34.135606 10815 net.cpp:408] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split -> rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_0
I0413 17:43:34.135617 10815 net.cpp:408] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split -> rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_1
I0413 17:43:34.135663 10815 net.cpp:150] Setting up rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 17:43:34.135673 10815 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 17:43:34.135679 10815 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 17:43:34.135684 10815 net.cpp:165] Memory required for data: 3585823860
I0413 17:43:34.135689 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_prob
I0413 17:43:34.135697 10815 net.cpp:100] Creating Layer rpn_big_cls_prob
I0413 17:43:34.135704 10815 net.cpp:434] rpn_big_cls_prob <- rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_0
I0413 17:43:34.135713 10815 net.cpp:408] rpn_big_cls_prob -> rpn_big_cls_prob
I0413 17:43:34.135788 10815 net.cpp:150] Setting up rpn_big_cls_prob
I0413 17:43:34.135798 10815 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 17:43:34.135803 10815 net.cpp:165] Memory required for data: 3586991156
I0413 17:43:34.135808 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_prob_reshape
I0413 17:43:34.135817 10815 net.cpp:100] Creating Layer rpn_big_cls_prob_reshape
I0413 17:43:34.135823 10815 net.cpp:434] rpn_big_cls_prob_reshape <- rpn_big_cls_prob
I0413 17:43:34.135833 10815 net.cpp:408] rpn_big_cls_prob_reshape -> rpn_big_cls_prob_reshape
I0413 17:43:34.135861 10815 net.cpp:150] Setting up rpn_big_cls_prob_reshape
I0413 17:43:34.135870 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135875 10815 net.cpp:165] Memory required for data: 3588158452
I0413 17:43:34.135880 10815 layer_factory.hpp:77] Creating layer rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 17:43:34.135888 10815 net.cpp:100] Creating Layer rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 17:43:34.135895 10815 net.cpp:434] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split <- rpn_big_cls_prob_reshape
I0413 17:43:34.135905 10815 net.cpp:408] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split -> rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_0
I0413 17:43:34.135915 10815 net.cpp:408] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split -> rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_1
I0413 17:43:34.135957 10815 net.cpp:150] Setting up rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 17:43:34.135967 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135974 10815 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 17:43:34.135978 10815 net.cpp:165] Memory required for data: 3590493044
I0413 17:43:34.135983 10815 layer_factory.hpp:77] Creating layer rpn_big_anchor_target
I0413 17:43:34.137791 10815 net.cpp:100] Creating Layer rpn_big_anchor_target
I0413 17:43:34.137814 10815 net.cpp:434] rpn_big_anchor_target <- rpn_big_cls_score_rpn_big_cls_score_0_split_1
I0413 17:43:34.137830 10815 net.cpp:434] rpn_big_anchor_target <- input_gt_boxes_input_2_split_0
I0413 17:43:34.137835 10815 net.cpp:434] rpn_big_anchor_target <- input_ignored_boxes
I0413 17:43:34.137840 10815 net.cpp:434] rpn_big_anchor_target <- input_im_info_input_1_split_0
I0413 17:43:34.137845 10815 net.cpp:434] rpn_big_anchor_target <- input_data_input_0_split_1
I0413 17:43:34.137852 10815 net.cpp:434] rpn_big_anchor_target <- rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_0
I0413 17:43:34.137864 10815 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_labels
I0413 17:43:34.137883 10815 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_bbox_targets
I0413 17:43:34.137898 10815 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_inside_weights
I0413 17:43:34.137912 10815 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_outside_weights
I0413 17:43:34.142729 10815 net.cpp:150] Setting up rpn_big_anchor_target
I0413 17:43:34.142753 10815 net.cpp:157] Top shape: 1 1 1586 92 (145912)
I0413 17:43:34.142760 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.142766 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.142773 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.142778 10815 net.cpp:165] Memory required for data: 3598080468
I0413 17:43:34.142786 10815 layer_factory.hpp:77] Creating layer rpn_big_loss_cls
I0413 17:43:34.142803 10815 net.cpp:100] Creating Layer rpn_big_loss_cls
I0413 17:43:34.142812 10815 net.cpp:434] rpn_big_loss_cls <- rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_1
I0413 17:43:34.142822 10815 net.cpp:434] rpn_big_loss_cls <- rpn_big_anchor_target_labels
I0413 17:43:34.142832 10815 net.cpp:408] rpn_big_loss_cls -> rpn_big_loss_cls
I0413 17:43:34.142848 10815 layer_factory.hpp:77] Creating layer rpn_big_loss_cls
I0413 17:43:34.143601 10815 net.cpp:150] Setting up rpn_big_loss_cls
I0413 17:43:34.143617 10815 net.cpp:157] Top shape: (1)
I0413 17:43:34.143621 10815 net.cpp:160]     with loss weight 1
I0413 17:43:34.143632 10815 net.cpp:165] Memory required for data: 3598080472
I0413 17:43:34.143640 10815 layer_factory.hpp:77] Creating layer rpn_big_output_box
I0413 17:43:34.143661 10815 net.cpp:100] Creating Layer rpn_big_output_box
I0413 17:43:34.143669 10815 net.cpp:434] rpn_big_output_box <- rpn_big_conv2_rpn_big_conv2_drop_0_split_1
I0413 17:43:34.143681 10815 net.cpp:408] rpn_big_output_box -> rpn_big_output_box
I0413 17:43:34.162715 10815 net.cpp:150] Setting up rpn_big_output_box
I0413 17:43:34.162744 10815 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 17:43:34.162757 10815 net.cpp:165] Memory required for data: 3607176664
I0413 17:43:34.162767 10815 layer_factory.hpp:77] Creating layer rpn_big_output_box_relu
I0413 17:43:34.162778 10815 net.cpp:100] Creating Layer rpn_big_output_box_relu
I0413 17:43:34.162784 10815 net.cpp:434] rpn_big_output_box_relu <- rpn_big_output_box
I0413 17:43:34.162801 10815 net.cpp:395] rpn_big_output_box_relu -> rpn_big_output_box (in-place)
I0413 17:43:34.162817 10815 net.cpp:150] Setting up rpn_big_output_box_relu
I0413 17:43:34.162834 10815 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 17:43:34.162847 10815 net.cpp:165] Memory required for data: 3616272856
I0413 17:43:34.162853 10815 layer_factory.hpp:77] Creating layer rpn_big_bbox_pred
I0413 17:43:34.162870 10815 net.cpp:100] Creating Layer rpn_big_bbox_pred
I0413 17:43:34.162878 10815 net.cpp:434] rpn_big_bbox_pred <- rpn_big_output_box
I0413 17:43:34.162889 10815 net.cpp:408] rpn_big_bbox_pred -> rpn_big_bbox_pred
I0413 17:43:34.168777 10815 net.cpp:150] Setting up rpn_big_bbox_pred
I0413 17:43:34.168797 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.168800 10815 net.cpp:165] Memory required for data: 3618607448
I0413 17:43:34.168810 10815 layer_factory.hpp:77] Creating layer rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 17:43:34.168823 10815 net.cpp:100] Creating Layer rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 17:43:34.168831 10815 net.cpp:434] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split <- rpn_big_bbox_pred
I0413 17:43:34.168844 10815 net.cpp:408] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split -> rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_0
I0413 17:43:34.168858 10815 net.cpp:408] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split -> rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_1
I0413 17:43:34.168913 10815 net.cpp:150] Setting up rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 17:43:34.168926 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.168934 10815 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 17:43:34.168939 10815 net.cpp:165] Memory required for data: 3623276632
I0413 17:43:34.168944 10815 layer_factory.hpp:77] Creating layer rpn_big_loss_bbox
I0413 17:43:34.169416 10815 net.cpp:100] Creating Layer rpn_big_loss_bbox
I0413 17:43:34.169430 10815 net.cpp:434] rpn_big_loss_bbox <- rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_0
I0413 17:43:34.169437 10815 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_bbox_targets
I0413 17:43:34.169445 10815 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_inside_weights
I0413 17:43:34.169452 10815 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_outside_weights
I0413 17:43:34.169463 10815 net.cpp:408] rpn_big_loss_bbox -> rpn_big_loss_bbox
I0413 17:43:34.171422 10815 net.cpp:150] Setting up rpn_big_loss_bbox
I0413 17:43:34.171458 10815 net.cpp:157] Top shape: 1 (1)
I0413 17:43:34.171460 10815 net.cpp:160]     with loss weight 1
I0413 17:43:34.171473 10815 net.cpp:165] Memory required for data: 3623276636
I0413 17:43:34.171478 10815 layer_factory.hpp:77] Creating layer proposal
I0413 17:43:34.171908 10815 net.cpp:100] Creating Layer proposal
I0413 17:43:34.171924 10815 net.cpp:434] proposal <- rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_1
I0413 17:43:34.171932 10815 net.cpp:434] proposal <- rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_1
I0413 17:43:34.171938 10815 net.cpp:434] proposal <- input_im_info_input_1_split_1
I0413 17:43:34.171946 10815 net.cpp:408] proposal -> rpn_rois
I0413 17:43:34.176172 10815 net.cpp:150] Setting up proposal
I0413 17:43:34.176193 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.176198 10815 net.cpp:165] Memory required for data: 3623276656
I0413 17:43:34.176203 10815 layer_factory.hpp:77] Creating layer roi-data
I0413 17:43:34.176574 10815 net.cpp:100] Creating Layer roi-data
I0413 17:43:34.176585 10815 net.cpp:434] roi-data <- rpn_rois
I0413 17:43:34.176594 10815 net.cpp:434] roi-data <- input_gt_boxes_input_2_split_1
I0413 17:43:34.176604 10815 net.cpp:408] roi-data -> rois
I0413 17:43:34.176620 10815 net.cpp:408] roi-data -> labels
I0413 17:43:34.176631 10815 net.cpp:408] roi-data -> bbox_targets
I0413 17:43:34.176645 10815 net.cpp:408] roi-data -> bbox_inside_weights
I0413 17:43:34.176658 10815 net.cpp:408] roi-data -> bbox_outside_weights
I0413 17:43:34.176669 10815 net.cpp:408] roi-data -> pid_label
I0413 17:43:34.177685 10815 net.cpp:150] Setting up roi-data
I0413 17:43:34.177697 10815 net.cpp:157] Top shape: 1 5 (5)
I0413 17:43:34.177701 10815 net.cpp:157] Top shape: 1 1 (1)
I0413 17:43:34.177708 10815 net.cpp:157] Top shape: 1 8 (8)
I0413 17:43:34.177716 10815 net.cpp:157] Top shape: 1 8 (8)
I0413 17:43:34.177722 10815 net.cpp:157] Top shape: 1 8 (8)
I0413 17:43:34.177728 10815 net.cpp:157] Top shape: (0)
I0413 17:43:34.177733 10815 net.cpp:165] Memory required for data: 3623276776
I0413 17:43:34.177738 10815 net.cpp:228] roi-data does not need backward computation.
I0413 17:43:34.177745 10815 net.cpp:228] proposal does not need backward computation.
I0413 17:43:34.177754 10815 net.cpp:226] rpn_big_loss_bbox needs backward computation.
I0413 17:43:34.177762 10815 net.cpp:226] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split needs backward computation.
I0413 17:43:34.177768 10815 net.cpp:226] rpn_big_bbox_pred needs backward computation.
I0413 17:43:34.177773 10815 net.cpp:226] rpn_big_output_box_relu needs backward computation.
I0413 17:43:34.177778 10815 net.cpp:226] rpn_big_output_box needs backward computation.
I0413 17:43:34.177784 10815 net.cpp:226] rpn_big_loss_cls needs backward computation.
I0413 17:43:34.177793 10815 net.cpp:226] rpn_big_anchor_target needs backward computation.
I0413 17:43:34.177803 10815 net.cpp:226] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split needs backward computation.
I0413 17:43:34.177810 10815 net.cpp:226] rpn_big_cls_prob_reshape needs backward computation.
I0413 17:43:34.177816 10815 net.cpp:226] rpn_big_cls_prob needs backward computation.
I0413 17:43:34.177821 10815 net.cpp:226] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split needs backward computation.
I0413 17:43:34.177827 10815 net.cpp:226] rpn_big_cls_score_reshape needs backward computation.
I0413 17:43:34.177834 10815 net.cpp:226] rpn_big_cls_score_rpn_big_cls_score_0_split needs backward computation.
I0413 17:43:34.177839 10815 net.cpp:226] rpn_big_cls_score needs backward computation.
I0413 17:43:34.177845 10815 net.cpp:226] rpn_big_output_cls_relu needs backward computation.
I0413 17:43:34.177850 10815 net.cpp:226] rpn_big_output_cls needs backward computation.
I0413 17:43:34.177856 10815 net.cpp:226] rpn_big_conv2_rpn_big_conv2_drop_0_split needs backward computation.
I0413 17:43:34.177863 10815 net.cpp:226] rpn_big_conv2_drop needs backward computation.
I0413 17:43:34.177870 10815 net.cpp:226] rpn_big_conv2_relu needs backward computation.
I0413 17:43:34.177875 10815 net.cpp:226] rpn_big_conv2 needs backward computation.
I0413 17:43:34.177881 10815 net.cpp:226] rpn_big_conv1_relu needs backward computation.
I0413 17:43:34.177887 10815 net.cpp:226] rpn_big_conv1 needs backward computation.
I0413 17:43:34.177893 10815 net.cpp:226] relu5_3 needs backward computation.
I0413 17:43:34.177898 10815 net.cpp:226] conv5_3 needs backward computation.
I0413 17:43:34.177903 10815 net.cpp:226] relu5_2 needs backward computation.
I0413 17:43:34.177908 10815 net.cpp:226] conv5_2 needs backward computation.
I0413 17:43:34.177914 10815 net.cpp:226] relu5_1 needs backward computation.
I0413 17:43:34.177919 10815 net.cpp:226] conv5_1 needs backward computation.
I0413 17:43:34.177924 10815 net.cpp:226] pool4 needs backward computation.
I0413 17:43:34.177929 10815 net.cpp:226] relu4_3 needs backward computation.
I0413 17:43:34.177935 10815 net.cpp:226] conv4_3 needs backward computation.
I0413 17:43:34.177940 10815 net.cpp:226] relu4_2 needs backward computation.
I0413 17:43:34.177945 10815 net.cpp:226] conv4_2 needs backward computation.
I0413 17:43:34.177952 10815 net.cpp:226] relu4_1 needs backward computation.
I0413 17:43:34.177955 10815 net.cpp:226] conv4_1 needs backward computation.
I0413 17:43:34.177961 10815 net.cpp:226] pool3 needs backward computation.
I0413 17:43:34.177968 10815 net.cpp:226] relu3_3 needs backward computation.
I0413 17:43:34.177973 10815 net.cpp:226] conv3_3 needs backward computation.
I0413 17:43:34.177978 10815 net.cpp:226] relu3_2 needs backward computation.
I0413 17:43:34.177983 10815 net.cpp:226] conv3_2 needs backward computation.
I0413 17:43:34.177989 10815 net.cpp:226] relu3_1 needs backward computation.
I0413 17:43:34.177994 10815 net.cpp:226] conv3_1 needs backward computation.
I0413 17:43:34.177999 10815 net.cpp:228] pool2 does not need backward computation.
I0413 17:43:34.178004 10815 net.cpp:228] relu2_2 does not need backward computation.
I0413 17:43:34.178009 10815 net.cpp:228] conv2_2 does not need backward computation.
I0413 17:43:34.178015 10815 net.cpp:228] relu2_1 does not need backward computation.
I0413 17:43:34.178020 10815 net.cpp:228] conv2_1 does not need backward computation.
I0413 17:43:34.178025 10815 net.cpp:228] pool1 does not need backward computation.
I0413 17:43:34.178031 10815 net.cpp:228] relu1_2 does not need backward computation.
I0413 17:43:34.178040 10815 net.cpp:228] conv1_2 does not need backward computation.
I0413 17:43:34.178045 10815 net.cpp:228] relu1_1 does not need backward computation.
I0413 17:43:34.178050 10815 net.cpp:228] conv1_1 does not need backward computation.
I0413 17:43:34.178057 10815 net.cpp:228] input_gt_boxes_input_2_split does not need backward computation.
I0413 17:43:34.178064 10815 net.cpp:228] input_im_info_input_1_split does not need backward computation.
I0413 17:43:34.178071 10815 net.cpp:228] input_data_input_0_split does not need backward computation.
I0413 17:43:34.178077 10815 net.cpp:228] input does not need backward computation.
I0413 17:43:34.178083 10815 net.cpp:270] This network produces output bbox_inside_weights
I0413 17:43:34.178088 10815 net.cpp:270] This network produces output bbox_outside_weights
I0413 17:43:34.178093 10815 net.cpp:270] This network produces output bbox_targets
I0413 17:43:34.178099 10815 net.cpp:270] This network produces output labels
I0413 17:43:34.178104 10815 net.cpp:270] This network produces output pid_label
I0413 17:43:34.178110 10815 net.cpp:270] This network produces output rois
I0413 17:43:34.178115 10815 net.cpp:270] This network produces output rpn_big_loss_bbox
I0413 17:43:34.178122 10815 net.cpp:270] This network produces output rpn_big_loss_cls
I0413 17:43:34.178189 10815 net.cpp:283] Network initialization done.
I0413 17:43:34.178387 10815 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from /home/mopkobka/CourseWork/DockerShared/gml-nn/data/NET/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0413 17:43:34.371482 10815 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/mopkobka/CourseWork/DockerShared/gml-nn/data/NET/VGG16.v2.caffemodel
I0413 17:43:34.371502 10815 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0413 17:43:34.371505 10815 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0413 17:43:34.382038 10815 net.cpp:761] Ignoring source layer pool5
I0413 17:43:34.382069 10815 net.cpp:761] Ignoring source layer fc6
I0413 17:43:34.382073 10815 net.cpp:761] Ignoring source layer relu6
I0413 17:43:34.382084 10815 net.cpp:761] Ignoring source layer drop6
I0413 17:43:34.382087 10815 net.cpp:761] Ignoring source layer fc7
I0413 17:43:34.382091 10815 net.cpp:761] Ignoring source layer relu7
I0413 17:43:34.382093 10815 net.cpp:761] Ignoring source layer drop7
I0413 17:43:34.382097 10815 net.cpp:761] Ignoring source layer fc8
I0413 17:43:34.382098 10815 net.cpp:761] Ignoring source layer prob
Solving...
F0413 17:43:34.594251 10815 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
exps/train_model.sh: line 26: 10815 Aborted                 (core dumped) python3 ./tools/train_net.py --gpu 0 --cfg exps/${EXP_NAME}/config.yml --exp_dir ${EXP_NAME} ${EXTRA_ARGS}
