+ echo Logging output to exps/example/logs/train_.txt.2017-04-13_18-18-52
Logging output to exps/example/logs/train_.txt.2017-04-13_18-18-52
+ python3 ./tools/train_net.py --gpu 0 --cfg exps/example/config.yml --exp_dir example
/home/mopkobka/CourseWork/venv-gml-nn/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
Called with args:
Namespace(cfg_file='exps/example/config.yml', exp_dir='example', gpu_id=0)
Using config:
{'DATA_DIR': '/home/mopkobka/CourseWork/gml-nn-detector/data',
 'DEDUP_BOXES': 0.0625,
 'DRAW_NET': False,
 'EPS': 1e-14,
 'EXP_DIR': 'example',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODEL': {'ATTACHED_NETS': [{'ANCHOR_RATIOS': [1.0],
                              'ANCHOR_SCALES': [3, 6, 9, 12],
                              'ANCHOR_SHIFT_NUM_XY': [[1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1]],
                              'ARCHITECTURE': "m.add_layer(ConvWithActivation(p('conv1'), "
                                              '128, 3))\n'
                                              "m.add_layer(ConvWithActivation(p('conv2'), "
                                              '128, 3, dropout=0.3),\n'
                                              '            parent_layer=-1)\n'
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_cls'), "
                                              '80, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))\n"
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_box'), "
                                              '80, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))",
                              'BATCHSIZE': 256,
                              'DISABLED': True,
                              'FG_FRACTION': 0.5,
                              'NAME': 'rpn_small',
                              'NEGATIVE_OVERLAP': 0.4,
                              'NMS_THRESH': 0.7,
                              'PARENT_LAYER': 'relu2_2',
                              'POSITIVE_OVERLAP': 0.6,
                              'POST_NMS_TOP_N': 500,
                              'PRE_NMS_TOP_N': 12000,
                              'SQUARE_TARGETS': True,
                              'TOP_NEGATIVE_FRACTION': 0.2,
                              'TYPE': 'RPN'},
                             {'ANCHOR_RATIOS': [1.0],
                              'ANCHOR_SCALES': [2.5,
                                                3.025,
                                                3.66025,
                                                4.4289024999999995,
                                                5.358972025,
                                                6.484356150249999,
                                                7.846070941802498,
                                                9.493745839581022,
                                                11.487432465893036,
                                                13.899793283730574,
                                                16.818749873313998,
                                                20.350687346709933,
                                                24.62433168951902,
                                                29.795441344318014],
                              'ANCHOR_SHIFT_NUM_XY': [[2, 2],
                                                      [2, 2],
                                                      [2, 2],
                                                      [2, 2],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1],
                                                      [1, 1]],
                              'ARCHITECTURE': "m.add_layer(ConvWithActivation(p('conv1'), "
                                              '512, 3))\n'
                                              "m.add_layer(ConvWithActivation(p('conv2'), "
                                              '512, 3, dropout=0.3),\n'
                                              '            parent_layer=-1)\n'
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_cls'), "
                                              '384, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))\n"
                                              '\n'
                                              "m.add_layer(ConvWithActivation(p('output_box'), "
                                              '384, 3),\n'
                                              '            '
                                              "parent_layer=p('conv2'))",
                              'BATCHSIZE': 256,
                              'FG_FRACTION': 0.5,
                              'NAME': 'rpn_big',
                              'NEGATIVE_OVERLAP': 0.4,
                              'NMS_THRESH': 0.7,
                              'PARENT_LAYER': 'relu5_3',
                              'POSITIVE_OVERLAP': 0.6,
                              'POST_NMS_TOP_N': 500,
                              'PRE_NMS_TOP_N': 12000,
                              'SQUARE_TARGETS': True,
                              'TOP_NEGATIVE_FRACTION': 0.2,
                              'TYPE': 'RPN'}],
           'NAME': 'faces_example',
           'PRETRAINED_MODEL_CONFIG': '/home/mopkobka/CourseWork/gml-nn-detector/models/vgg16/model.prototxt',
           'WEIGHTS_PATH': '/home/mopkobka/CourseWork/DockerShared/gml-nn/data/NET/VGG16.v2.caffemodel'},
 'MODELS_DIR': '/home/mopkobka/CourseWork/gml-nn-detector/models',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 777,
 'ROOT_DIR': '/home/mopkobka/CourseWork/gml-nn-detector',
 'RPN': {'ANCHOR_BASE_SIZE': 16,
         'ANCHOR_RATIOS': [0.5, 1, 2],
         'ANCHOR_SCALES': [8, 16, 32],
         'ANCHOR_SHIFT_NUM_XY': [(1, 1)]},
 'TEST': {'BBOX_REG': True,
          'DATASETS': [{'MAX_SIZE': 1400,
                        'OUTPUT_FILE': 'videoset.json',
                        'PATH': '/home/local/work/data/faces/BigSampleFNTest_p3lr11/imgs',
                        'SCALES': [350, 1000],
                        'TYPE': 'IMAGES_DIR'},
                       {'MAX_SIZE': 700,
                        'OUTPUT_FILE': 'fddb.json',
                        'PATH': '/home/local/work/data/faces/FDDB/FDDB_p3lr11/imgs',
                        'SCALES': [500],
                        'TYPE': 'IMAGES_DIR'}],
          'DENSE_SCAN': False,
          'FINAL_NMS': 0.5,
          'HAS_RPN': False,
          'MAX_PER_IMAGE': 200,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_ONLY': False,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'VIZUALIZATION': {'DRAW_BOXES': True,
                            'DRAW_SCORES': False,
                            'ENABLE': False,
                            'ONLY_WITH_OBJECTS': False,
                            'SCORE_THRESH': 0.5},
          'WITHOUT_UPSAMPLE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'DATASET': 'default',
           'DATASETS': [{'MAX_SIZE': 700,
                         'PATH': '/home/mopkobka/CourseWork/DockerShared/gml-nn/tiny_dataset',
                         'SCALES': [500],
                         'TYPE': 'BBOX_JSON_MARKING'}],
           'DOUBLE_GENERATE': False,
           'ENABLE_SMART_ORDER': False,
           'GENERATED_FRACTION': 0.0,
           'HAS_RPN': True,
           'PROPOSAL_METHOD': 'selective_search',
           'RATIO_JITTERING': 0.0,
           'REDISTRIBUTE_CLASSES': False,
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_LINEAR_START_TNF': 0.1,
           'RPN_LINEAR_TNF_K': -1.0,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_PERIODIC_TN': 0,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_SQUARE_TARGETS': False,
           'RPN_SQUARE_TARGETS_KY': False,
           'RPN_TOP_NEGATIVE_FRACTION': 0.0,
           'SCALE_JITTERING': 0.0,
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'SOLVER': {'BASE_LR': 0.001,
                      'DISPLAY': {'AVERAGE_LOSS': 100, 'PERIOD': 20},
                      'IMS_PER_BATCH': 2,
                      'LR_POLICY': {'GAMMA': 0.1,
                                    'STEPS': [70000, 120000],
                                    'TYPE': 'multistep'},
                      'MOMENTUM': 0.9,
                      'TRAIN_ITERS': 90000,
                      'WEIGHT_DECAY': 0.0005},
           'SO_FORCE_BATCHSIZE': 500,
           'SO_FORCE_ROUNDS': 8,
           'SO_GOOD_SKIP_PROB': 0.85,
           'SO_TAIL_LEN': 1000,
           'USE_FLIPPED': True,
           'USE_LMDB': False,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True,
 'WEIGHTS_PATH': 'default'}
Output will be saved to `/home/mopkobka/CourseWork/gml-nn-detector/exps/example/output/train_13_04_2017_18_18`
Created solver path: /tmp/tmpsxx4o7ot
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> /tmp/tmpsxx4o7ot
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 18:18:53.657840 12922 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.001
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 0
snapshot_prefix: "faces_example"
net_param {
  name: "GeneratedModel_13_04_2017_18_18"
  layer {
    name: "input"
    type: "Python"
    top: "input_data"
    top: "input_im_info"
    top: "input_gt_boxes"
    top: "input_ignored_boxes"
    python_param {
      module: "layers.roi_data_layer"
      layer: "RoIDataLayer"
      param_str: "{\"num_classes\": 2}"
    }
  }
  layer {
    name: "conv1_1"
    type: "Convolution"
    bottom: "input_data"
    top: "conv1_1"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu1_1"
    type: "ReLU"
    bottom: "conv1_1"
    top: "conv1_1"
  }
  layer {
    name: "conv1_2"
    type: "Convolution"
    bottom: "conv1_1"
    top: "conv1_2"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu1_2"
    type: "ReLU"
    bottom: "conv1_2"
    top: "conv1_2"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1_2"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv2_1"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu2_1"
    type: "ReLU"
    bottom: "conv2_1"
    top: "conv2_1"
  }
  layer {
    name: "conv2_2"
    type: "Convolution"
    bottom: "conv2_1"
    top: "conv2_2"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu2_2"
    type: "ReLU"
    bottom: "conv2_2"
    top: "conv2_2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "conv2_2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv3_1"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_1"
    type: "ReLU"
    bottom: "conv3_1"
    top: "conv3_1"
  }
  layer {
    name: "conv3_2"
    type: "Convolution"
    bottom: "conv3_1"
    top: "conv3_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_2"
    type: "ReLU"
    bottom: "conv3_2"
    top: "conv3_2"
  }
  layer {
    name: "conv3_3"
    type: "Convolution"
    bottom: "conv3_2"
    top: "conv3_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu3_3"
    type: "ReLU"
    bottom: "conv3_3"
    top: "conv3_3"
  }
  layer {
    name: "pool3"
    type: "Pooling"
    bottom: "conv3_3"
    top: "pool3"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv4_1"
    type: "Convolution"
    bottom: "pool3"
    top: "conv4_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_1"
    type: "ReLU"
    bottom: "conv4_1"
    top: "conv4_1"
  }
  layer {
    name: "conv4_2"
    type: "Convolution"
    bottom: "conv4_1"
    top: "conv4_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_2"
    type: "ReLU"
    bottom: "conv4_2"
    top: "conv4_2"
  }
  layer {
    name: "conv4_3"
    type: "Convolution"
    bottom: "conv4_2"
    top: "conv4_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu4_3"
    type: "ReLU"
    bottom: "conv4_3"
    top: "conv4_3"
  }
  layer {
    name: "pool4"
    type: "Pooling"
    bottom: "conv4_3"
    top: "pool4"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "conv5_1"
    type: "Convolution"
    bottom: "pool4"
    top: "conv5_1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_1"
    type: "ReLU"
    bottom: "conv5_1"
    top: "conv5_1"
  }
  layer {
    name: "conv5_2"
    type: "Convolution"
    bottom: "conv5_1"
    top: "conv5_2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_2"
    type: "ReLU"
    bottom: "conv5_2"
    top: "conv5_2"
  }
  layer {
    name: "conv5_3"
    type: "Convolution"
    bottom: "conv5_2"
    top: "conv5_3"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
    }
  }
  layer {
    name: "relu5_3"
    type: "ReLU"
    bottom: "conv5_3"
    top: "conv5_3"
  }
  layer {
    name: "rpn_big_conv1"
    type: "Convolution"
    bottom: "conv5_3"
    top: "rpn_big_conv1"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_conv1_relu"
    type: "ReLU"
    bottom: "rpn_big_conv1"
    top: "rpn_big_conv1"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_conv2"
    type: "Convolution"
    bottom: "rpn_big_conv1"
    top: "rpn_big_conv2"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 512
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_conv2_relu"
    type: "ReLU"
    bottom: "rpn_big_conv2"
    top: "rpn_big_conv2"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_conv2_drop"
    type: "Dropout"
    bottom: "rpn_big_conv2"
    top: "rpn_big_conv2"
    dropout_param {
      dropout_ratio: 0.3
    }
  }
  layer {
    name: "rpn_big_output_cls"
    type: "Convolution"
    bottom: "rpn_big_conv2"
    top: "rpn_big_output_cls"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_output_cls_relu"
    type: "ReLU"
    bottom: "rpn_big_output_cls"
    top: "rpn_big_output_cls"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_cls_score"
    type: "Convolution"
    bottom: "rpn_big_output_cls"
    top: "rpn_big_cls_score"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 52
      pad: 0
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_cls_score_reshape"
    type: "Reshape"
    bottom: "rpn_big_cls_score"
    top: "rpn_big_cls_score_reshape"
    reshape_param {
      shape {
        dim: 0
        dim: 2
        dim: -1
        dim: 0
      }
    }
  }
  layer {
    name: "rpn_big_cls_prob"
    type: "Softmax"
    bottom: "rpn_big_cls_score_reshape"
    top: "rpn_big_cls_prob"
  }
  layer {
    name: "rpn_big_cls_prob_reshape"
    type: "Reshape"
    bottom: "rpn_big_cls_prob"
    top: "rpn_big_cls_prob_reshape"
    reshape_param {
      shape {
        dim: 0
        dim: 52
        dim: -1
        dim: 0
      }
    }
  }
  layer {
    name: "rpn_big_anchor_target"
    type: "Python"
    bottom: "rpn_big_cls_score"
    bottom: "input_gt_boxes"
    bottom: "input_ignored_boxes"
    bottom: "input_im_info"
    bottom: "input_data"
    bottom: "rpn_big_cls_prob_reshape"
    top: "rpn_big_anchor_target_labels"
    top: "rpn_big_anchor_target_bbox_targets"
    top: "rpn_big_anchor_target_inside_weights"
    top: "rpn_big_anchor_target_outside_weights"
    python_param {
      module: "rpn.anchor_target_layer"
      layer: "AnchorTargetLayer"
      param_str: "{\"fg_fraction\": 0.5, \"tn_fraction\": 0.2, \"square_targets\": true, \"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"negative_overlap\": 0.4, \"positive_overlap\": 0.6, \"name\": \"rpn_big\", \"anchor_ratios\": [1.0], \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"num_classes\": 1, \"batchsize\": 256, \"feat_stride\": 16}"
    }
  }
  layer {
    name: "rpn_big_loss_cls"
    type: "SoftmaxWithLoss"
    bottom: "rpn_big_cls_score_reshape"
    bottom: "rpn_big_anchor_target_labels"
    top: "rpn_big_loss_cls"
    loss_weight: 1
    propagate_down: true
    propagate_down: false
    loss_param {
      ignore_label: -1
      normalization: VALID
    }
  }
  layer {
    name: "rpn_big_output_box"
    type: "Convolution"
    bottom: "rpn_big_conv2"
    top: "rpn_big_output_box"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_output_box_relu"
    type: "ReLU"
    bottom: "rpn_big_output_box"
    top: "rpn_big_output_box"
    relu_param {
      negative_slope: 0
    }
  }
  layer {
    name: "rpn_big_bbox_pred"
    type: "Convolution"
    bottom: "rpn_big_output_box"
    top: "rpn_big_bbox_pred"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    convolution_param {
      num_output: 104
      pad: 0
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "rpn_big_loss_bbox"
    type: "Python"
    bottom: "rpn_big_bbox_pred"
    bottom: "rpn_big_anchor_target_bbox_targets"
    bottom: "rpn_big_anchor_target_inside_weights"
    bottom: "rpn_big_anchor_target_outside_weights"
    top: "rpn_big_loss_bbox"
    loss_weight: 1
    python_param {
      module: "layers.smooth_l1_loss"
      layer: "SmoothL1LossLayer"
      param_str: "{\"sigma\": 3}"
    }
  }
  layer {
    name: "proposal"
    type: "Python"
    bottom: "rpn_big_cls_prob_reshape"
    bottom: "rpn_big_bbox_pred"
    bottom: "input_im_info"
    top: "rpn_rois"
    python_param {
      module: "rpn.proposal_layer"
      layer: "ProposalLayer"
      param_str: "{\"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"feat_stride\": 16, \"num_classes\": 1, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"square_targets\": true, \"name\": \"rpn_big\", \"batchsize\": 256, \"anchor_ratios\": [1.0]}"
    }
  }
  layer {
    name: "roi-data"
    type: "Python"
    bottom: "rpn_rois"
    bottom: "input_gt_boxes"
    top: "rois"
    top: "labels"
    top: "bbox_targets"
    top: "bbox_inside_weights"
    top: "bbox_outside_weights"
    top: "pid_label"
    python_param {
      module: "rpn.proposal_target_layer"
      layer: "ProposalTargetLayer"
      param_str: "{\"num_classes\": 2, \"bg_aux_label\": 5532}"
    }
  }
  layer {
    name: "roi-pool"
    type: "ROIPooling"
    bottom: "conv5_3"
    bottom: "rois"
    top: "roi-pool"
    roi_pooling_param {
      pooled_h: 7
      pooled_w: 7
      spatial_scale: 0.0625
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "roi-pool"
    top: "fc6"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    inner_product_param {
      num_output: 4096
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "fc6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "fc6"
    top: "fc6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "fc6"
    top: "fc7"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    inner_product_param {
      num_output: 4096
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "fc7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "fc7"
    top: "fc7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "bbox_pred"
    type: "InnerProduct"
    bottom: "fc7"
    top: "bbox_pred"
    param {
      lr_mult: 1
    }
    param {
      lr_mult: 2
    }
    inner_product_param {
      num_output: 0
      weight_filler {
        type: "gaussian"
        std: 0.001
      }
      bias_filler {
        type: "constant"
        value: 0
      }
    }
  }
  layer {
    name: "loss_bbox"
    type: "SmoothL1Loss"
    bottom: "bbox_pred"
    bottom: "bbox_targets"
    bottom: "bbox_inside_weights"
    bottom: "bbox_outside_weights"
    top: "loss_bbox"
    loss_weight: 1
  }
}
average_loss: 100
stepvalue: 70000
stepvalue: 120000
iter_size: 2
I0413 18:18:53.657927 12922 solver.cpp:86] Creating training net specified in net_param.
I0413 18:18:53.658360 12922 net.cpp:58] Initializing net from parameters: 
name: "GeneratedModel_13_04_2017_18_18"
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Python"
  top: "input_data"
  top: "input_im_info"
  top: "input_gt_boxes"
  top: "input_ignored_boxes"
  python_param {
    module: "layers.roi_data_layer"
    layer: "RoIDataLayer"
    param_str: "{\"num_classes\": 2}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "input_data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_big_conv1"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn_big_conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_conv1_relu"
  type: "ReLU"
  bottom: "rpn_big_conv1"
  top: "rpn_big_conv1"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_conv2"
  type: "Convolution"
  bottom: "rpn_big_conv1"
  top: "rpn_big_conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_conv2_relu"
  type: "ReLU"
  bottom: "rpn_big_conv2"
  top: "rpn_big_conv2"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_conv2_drop"
  type: "Dropout"
  bottom: "rpn_big_conv2"
  top: "rpn_big_conv2"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "rpn_big_output_cls"
  type: "Convolution"
  bottom: "rpn_big_conv2"
  top: "rpn_big_output_cls"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_output_cls_relu"
  type: "ReLU"
  bottom: "rpn_big_output_cls"
  top: "rpn_big_output_cls"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_cls_score"
  type: "Convolution"
  bottom: "rpn_big_output_cls"
  top: "rpn_big_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 52
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_big_cls_score"
  top: "rpn_big_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_big_cls_prob"
  type: "Softmax"
  bottom: "rpn_big_cls_score_reshape"
  top: "rpn_big_cls_prob"
}
layer {
  name: "rpn_big_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_big_cls_prob"
  top: "rpn_big_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 52
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_big_anchor_target"
  type: "Python"
  bottom: "rpn_big_cls_score"
  bottom: "input_gt_boxes"
  bottom: "input_ignored_boxes"
  bottom: "input_im_info"
  bottom: "input_data"
  bottom: "rpn_big_cls_prob_reshape"
  top: "rpn_big_anchor_target_labels"
  top: "rpn_big_anchor_target_bbox_targets"
  top: "rpn_big_anchor_target_inside_weights"
  top: "rpn_big_anchor_target_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "{\"fg_fraction\": 0.5, \"tn_fraction\": 0.2, \"square_targets\": true, \"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"negative_overlap\": 0.4, \"positive_overlap\": 0.6, \"name\": \"rpn_big\", \"anchor_ratios\": [1.0], \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"num_classes\": 1, \"batchsize\": 256, \"feat_stride\": 16}"
  }
}
layer {
  name: "rpn_big_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_big_cls_score_reshape"
  bottom: "rpn_big_anchor_target_labels"
  top: "rpn_big_loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalization: VALID
  }
}
layer {
  name: "rpn_big_output_box"
  type: "Convolution"
  bottom: "rpn_big_conv2"
  top: "rpn_big_output_box"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_output_box_relu"
  type: "ReLU"
  bottom: "rpn_big_output_box"
  top: "rpn_big_output_box"
  relu_param {
    negative_slope: 0
  }
}
layer {
  name: "rpn_big_bbox_pred"
  type: "Convolution"
  bottom: "rpn_big_output_box"
  top: "rpn_big_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 104
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "rpn_big_loss_bbox"
  type: "Python"
  bottom: "rpn_big_bbox_pred"
  bottom: "rpn_big_anchor_target_bbox_targets"
  bottom: "rpn_big_anchor_target_inside_weights"
  bottom: "rpn_big_anchor_target_outside_weights"
  top: "rpn_big_loss_bbox"
  loss_weight: 1
  python_param {
    module: "layers.smooth_l1_loss"
    layer: "SmoothL1LossLayer"
    param_str: "{\"sigma\": 3}"
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_big_cls_prob_reshape"
  bottom: "rpn_big_bbox_pred"
  bottom: "input_im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "{\"anchor_shift_num_xy\": [[2, 2], [2, 2], [2, 2], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1]], \"feat_stride\": 16, \"num_classes\": 1, \"anchor_scales\": [2.5, 3.025, 3.66025, 4.4289024999999995, 5.358972025, 6.484356150249999, 7.846070941802498, 9.493745839581022, 11.487432465893036, 13.899793283730574, 16.818749873313998, 20.350687346709933, 24.62433168951902, 29.795441344318014], \"square_targets\": true, \"name\": \"rpn_big\", \"batchsize\": 256, \"anchor_ratios\": [1.0]}"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "input_gt_boxes"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "pid_label"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "{\"num_classes\": 2, \"bg_aux_label\": 5532}"
  }
}
layer {
  name: "roi-pool"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "roi-pool"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "roi-pool"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 0
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 1
}
I0413 18:18:53.658588 12922 layer_factory.hpp:77] Creating layer input
I0413 18:18:53.659823 12922 net.cpp:100] Creating Layer input
I0413 18:18:53.659839 12922 net.cpp:408] input -> input_data
I0413 18:18:53.659850 12922 net.cpp:408] input -> input_im_info
I0413 18:18:53.659857 12922 net.cpp:408] input -> input_gt_boxes
I0413 18:18:53.659864 12922 net.cpp:408] input -> input_ignored_boxes
RoiDataLayer: name_to_top: {'ignored_boxes': 3, 'im_info': 1, 'data': 0, 'gt_boxes': 2}
I0413 18:18:53.984779 12922 net.cpp:150] Setting up input
I0413 18:18:53.984827 12922 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 18:18:53.984838 12922 net.cpp:157] Top shape: 1 3 (3)
I0413 18:18:53.984845 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:53.984855 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:53.984863 12922 net.cpp:165] Memory required for data: 18000052
I0413 18:18:53.984872 12922 layer_factory.hpp:77] Creating layer input_data_input_0_split
I0413 18:18:53.984890 12922 net.cpp:100] Creating Layer input_data_input_0_split
I0413 18:18:53.984899 12922 net.cpp:434] input_data_input_0_split <- input_data
I0413 18:18:53.984920 12922 net.cpp:408] input_data_input_0_split -> input_data_input_0_split_0
I0413 18:18:53.984941 12922 net.cpp:408] input_data_input_0_split -> input_data_input_0_split_1
I0413 18:18:53.984985 12922 net.cpp:150] Setting up input_data_input_0_split
I0413 18:18:53.984997 12922 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 18:18:53.985004 12922 net.cpp:157] Top shape: 1 3 1000 1500 (4500000)
I0413 18:18:53.985010 12922 net.cpp:165] Memory required for data: 54000052
I0413 18:18:53.985016 12922 layer_factory.hpp:77] Creating layer input_im_info_input_1_split
I0413 18:18:53.985028 12922 net.cpp:100] Creating Layer input_im_info_input_1_split
I0413 18:18:53.985034 12922 net.cpp:434] input_im_info_input_1_split <- input_im_info
I0413 18:18:53.985047 12922 net.cpp:408] input_im_info_input_1_split -> input_im_info_input_1_split_0
I0413 18:18:53.985059 12922 net.cpp:408] input_im_info_input_1_split -> input_im_info_input_1_split_1
I0413 18:18:53.985097 12922 net.cpp:150] Setting up input_im_info_input_1_split
I0413 18:18:53.985106 12922 net.cpp:157] Top shape: 1 3 (3)
I0413 18:18:53.985115 12922 net.cpp:157] Top shape: 1 3 (3)
I0413 18:18:53.985121 12922 net.cpp:165] Memory required for data: 54000076
I0413 18:18:53.985127 12922 layer_factory.hpp:77] Creating layer input_gt_boxes_input_2_split
I0413 18:18:53.985137 12922 net.cpp:100] Creating Layer input_gt_boxes_input_2_split
I0413 18:18:53.985146 12922 net.cpp:434] input_gt_boxes_input_2_split <- input_gt_boxes
I0413 18:18:53.985157 12922 net.cpp:408] input_gt_boxes_input_2_split -> input_gt_boxes_input_2_split_0
I0413 18:18:53.985170 12922 net.cpp:408] input_gt_boxes_input_2_split -> input_gt_boxes_input_2_split_1
I0413 18:18:53.985208 12922 net.cpp:150] Setting up input_gt_boxes_input_2_split
I0413 18:18:53.985218 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:53.985227 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:53.985234 12922 net.cpp:165] Memory required for data: 54000116
I0413 18:18:53.985241 12922 layer_factory.hpp:77] Creating layer conv1_1
I0413 18:18:53.985260 12922 net.cpp:100] Creating Layer conv1_1
I0413 18:18:53.985266 12922 net.cpp:434] conv1_1 <- input_data_input_0_split_0
I0413 18:18:53.985280 12922 net.cpp:408] conv1_1 -> conv1_1
I0413 18:18:53.988437 12922 net.cpp:150] Setting up conv1_1
I0413 18:18:53.988476 12922 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 18:18:53.988482 12922 net.cpp:165] Memory required for data: 438000116
I0413 18:18:53.988507 12922 layer_factory.hpp:77] Creating layer relu1_1
I0413 18:18:53.988523 12922 net.cpp:100] Creating Layer relu1_1
I0413 18:18:53.988533 12922 net.cpp:434] relu1_1 <- conv1_1
I0413 18:18:53.988544 12922 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0413 18:18:53.988561 12922 net.cpp:150] Setting up relu1_1
I0413 18:18:53.988571 12922 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 18:18:53.988579 12922 net.cpp:165] Memory required for data: 822000116
I0413 18:18:53.988585 12922 layer_factory.hpp:77] Creating layer conv1_2
I0413 18:18:53.988606 12922 net.cpp:100] Creating Layer conv1_2
I0413 18:18:53.988615 12922 net.cpp:434] conv1_2 <- conv1_1
I0413 18:18:53.988631 12922 net.cpp:408] conv1_2 -> conv1_2
I0413 18:18:53.994220 12922 net.cpp:150] Setting up conv1_2
I0413 18:18:53.994261 12922 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 18:18:53.994266 12922 net.cpp:165] Memory required for data: 1206000116
I0413 18:18:53.994295 12922 layer_factory.hpp:77] Creating layer relu1_2
I0413 18:18:53.994312 12922 net.cpp:100] Creating Layer relu1_2
I0413 18:18:53.994320 12922 net.cpp:434] relu1_2 <- conv1_2
I0413 18:18:53.994335 12922 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0413 18:18:53.994355 12922 net.cpp:150] Setting up relu1_2
I0413 18:18:53.994364 12922 net.cpp:157] Top shape: 1 64 1000 1500 (96000000)
I0413 18:18:53.994369 12922 net.cpp:165] Memory required for data: 1590000116
I0413 18:18:53.994377 12922 layer_factory.hpp:77] Creating layer pool1
I0413 18:18:53.994391 12922 net.cpp:100] Creating Layer pool1
I0413 18:18:53.994397 12922 net.cpp:434] pool1 <- conv1_2
I0413 18:18:53.994410 12922 net.cpp:408] pool1 -> pool1
I0413 18:18:53.994485 12922 net.cpp:150] Setting up pool1
I0413 18:18:53.994495 12922 net.cpp:157] Top shape: 1 64 500 750 (24000000)
I0413 18:18:53.994501 12922 net.cpp:165] Memory required for data: 1686000116
I0413 18:18:53.994510 12922 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:18:53.994529 12922 net.cpp:100] Creating Layer conv2_1
I0413 18:18:53.994536 12922 net.cpp:434] conv2_1 <- pool1
I0413 18:18:53.994549 12922 net.cpp:408] conv2_1 -> conv2_1
I0413 18:18:53.995887 12922 net.cpp:150] Setting up conv2_1
I0413 18:18:53.995916 12922 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 18:18:53.995921 12922 net.cpp:165] Memory required for data: 1878000116
I0413 18:18:53.995945 12922 layer_factory.hpp:77] Creating layer relu2_1
I0413 18:18:53.995960 12922 net.cpp:100] Creating Layer relu2_1
I0413 18:18:53.995968 12922 net.cpp:434] relu2_1 <- conv2_1
I0413 18:18:53.995981 12922 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0413 18:18:53.995995 12922 net.cpp:150] Setting up relu2_1
I0413 18:18:53.996004 12922 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 18:18:53.996011 12922 net.cpp:165] Memory required for data: 2070000116
I0413 18:18:53.996017 12922 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:18:53.996031 12922 net.cpp:100] Creating Layer conv2_2
I0413 18:18:53.996037 12922 net.cpp:434] conv2_2 <- conv2_1
I0413 18:18:53.996048 12922 net.cpp:408] conv2_2 -> conv2_2
I0413 18:18:53.997040 12922 net.cpp:150] Setting up conv2_2
I0413 18:18:53.997064 12922 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 18:18:53.997069 12922 net.cpp:165] Memory required for data: 2262000116
I0413 18:18:53.997082 12922 layer_factory.hpp:77] Creating layer relu2_2
I0413 18:18:53.997098 12922 net.cpp:100] Creating Layer relu2_2
I0413 18:18:53.997107 12922 net.cpp:434] relu2_2 <- conv2_2
I0413 18:18:53.997117 12922 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0413 18:18:53.997130 12922 net.cpp:150] Setting up relu2_2
I0413 18:18:53.997139 12922 net.cpp:157] Top shape: 1 128 500 750 (48000000)
I0413 18:18:53.997148 12922 net.cpp:165] Memory required for data: 2454000116
I0413 18:18:53.997153 12922 layer_factory.hpp:77] Creating layer pool2
I0413 18:18:53.997166 12922 net.cpp:100] Creating Layer pool2
I0413 18:18:53.997174 12922 net.cpp:434] pool2 <- conv2_2
I0413 18:18:53.997184 12922 net.cpp:408] pool2 -> pool2
I0413 18:18:53.997231 12922 net.cpp:150] Setting up pool2
I0413 18:18:53.997241 12922 net.cpp:157] Top shape: 1 128 250 375 (12000000)
I0413 18:18:53.997247 12922 net.cpp:165] Memory required for data: 2502000116
I0413 18:18:53.997256 12922 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:18:53.997272 12922 net.cpp:100] Creating Layer conv3_1
I0413 18:18:53.997278 12922 net.cpp:434] conv3_1 <- pool2
I0413 18:18:53.997290 12922 net.cpp:408] conv3_1 -> conv3_1
I0413 18:18:53.998383 12922 net.cpp:150] Setting up conv3_1
I0413 18:18:53.998409 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:53.998415 12922 net.cpp:165] Memory required for data: 2598000116
I0413 18:18:53.998436 12922 layer_factory.hpp:77] Creating layer relu3_1
I0413 18:18:53.998448 12922 net.cpp:100] Creating Layer relu3_1
I0413 18:18:53.998457 12922 net.cpp:434] relu3_1 <- conv3_1
I0413 18:18:53.998471 12922 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0413 18:18:53.998484 12922 net.cpp:150] Setting up relu3_1
I0413 18:18:53.998494 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:53.998502 12922 net.cpp:165] Memory required for data: 2694000116
I0413 18:18:53.998508 12922 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:18:53.998529 12922 net.cpp:100] Creating Layer conv3_2
I0413 18:18:53.998536 12922 net.cpp:434] conv3_2 <- conv3_1
I0413 18:18:53.998546 12922 net.cpp:408] conv3_2 -> conv3_2
I0413 18:18:54.000389 12922 net.cpp:150] Setting up conv3_2
I0413 18:18:54.000425 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:54.000432 12922 net.cpp:165] Memory required for data: 2790000116
I0413 18:18:54.000447 12922 layer_factory.hpp:77] Creating layer relu3_2
I0413 18:18:54.000461 12922 net.cpp:100] Creating Layer relu3_2
I0413 18:18:54.000470 12922 net.cpp:434] relu3_2 <- conv3_2
I0413 18:18:54.000483 12922 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0413 18:18:54.000499 12922 net.cpp:150] Setting up relu3_2
I0413 18:18:54.000507 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:54.000515 12922 net.cpp:165] Memory required for data: 2886000116
I0413 18:18:54.000521 12922 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:18:54.000535 12922 net.cpp:100] Creating Layer conv3_3
I0413 18:18:54.000543 12922 net.cpp:434] conv3_3 <- conv3_2
I0413 18:18:54.000555 12922 net.cpp:408] conv3_3 -> conv3_3
I0413 18:18:54.002619 12922 net.cpp:150] Setting up conv3_3
I0413 18:18:54.002661 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:54.002668 12922 net.cpp:165] Memory required for data: 2982000116
I0413 18:18:54.002683 12922 layer_factory.hpp:77] Creating layer relu3_3
I0413 18:18:54.002696 12922 net.cpp:100] Creating Layer relu3_3
I0413 18:18:54.002704 12922 net.cpp:434] relu3_3 <- conv3_3
I0413 18:18:54.002717 12922 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0413 18:18:54.002733 12922 net.cpp:150] Setting up relu3_3
I0413 18:18:54.002741 12922 net.cpp:157] Top shape: 1 256 250 375 (24000000)
I0413 18:18:54.002746 12922 net.cpp:165] Memory required for data: 3078000116
I0413 18:18:54.002751 12922 layer_factory.hpp:77] Creating layer pool3
I0413 18:18:54.002761 12922 net.cpp:100] Creating Layer pool3
I0413 18:18:54.002768 12922 net.cpp:434] pool3 <- conv3_3
I0413 18:18:54.002777 12922 net.cpp:408] pool3 -> pool3
I0413 18:18:54.002835 12922 net.cpp:150] Setting up pool3
I0413 18:18:54.002846 12922 net.cpp:157] Top shape: 1 256 125 188 (6016000)
I0413 18:18:54.002851 12922 net.cpp:165] Memory required for data: 3102064116
I0413 18:18:54.002856 12922 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:18:54.002873 12922 net.cpp:100] Creating Layer conv4_1
I0413 18:18:54.002881 12922 net.cpp:434] conv4_1 <- pool3
I0413 18:18:54.002892 12922 net.cpp:408] conv4_1 -> conv4_1
I0413 18:18:54.005802 12922 net.cpp:150] Setting up conv4_1
I0413 18:18:54.005841 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.005848 12922 net.cpp:165] Memory required for data: 3150192116
I0413 18:18:54.005863 12922 layer_factory.hpp:77] Creating layer relu4_1
I0413 18:18:54.005880 12922 net.cpp:100] Creating Layer relu4_1
I0413 18:18:54.005888 12922 net.cpp:434] relu4_1 <- conv4_1
I0413 18:18:54.005904 12922 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0413 18:18:54.005920 12922 net.cpp:150] Setting up relu4_1
I0413 18:18:54.005931 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.005937 12922 net.cpp:165] Memory required for data: 3198320116
I0413 18:18:54.005945 12922 layer_factory.hpp:77] Creating layer conv4_2
I0413 18:18:54.005964 12922 net.cpp:100] Creating Layer conv4_2
I0413 18:18:54.005970 12922 net.cpp:434] conv4_2 <- conv4_1
I0413 18:18:54.005980 12922 net.cpp:408] conv4_2 -> conv4_2
I0413 18:18:54.010380 12922 net.cpp:150] Setting up conv4_2
I0413 18:18:54.010419 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.010426 12922 net.cpp:165] Memory required for data: 3246448116
I0413 18:18:54.010448 12922 layer_factory.hpp:77] Creating layer relu4_2
I0413 18:18:54.010464 12922 net.cpp:100] Creating Layer relu4_2
I0413 18:18:54.010474 12922 net.cpp:434] relu4_2 <- conv4_2
I0413 18:18:54.010488 12922 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0413 18:18:54.010502 12922 net.cpp:150] Setting up relu4_2
I0413 18:18:54.010514 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.010520 12922 net.cpp:165] Memory required for data: 3294576116
I0413 18:18:54.010527 12922 layer_factory.hpp:77] Creating layer conv4_3
I0413 18:18:54.010546 12922 net.cpp:100] Creating Layer conv4_3
I0413 18:18:54.010553 12922 net.cpp:434] conv4_3 <- conv4_2
I0413 18:18:54.010565 12922 net.cpp:408] conv4_3 -> conv4_3
I0413 18:18:54.014968 12922 net.cpp:150] Setting up conv4_3
I0413 18:18:54.015007 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.015013 12922 net.cpp:165] Memory required for data: 3342704116
I0413 18:18:54.015029 12922 layer_factory.hpp:77] Creating layer relu4_3
I0413 18:18:54.015046 12922 net.cpp:100] Creating Layer relu4_3
I0413 18:18:54.015054 12922 net.cpp:434] relu4_3 <- conv4_3
I0413 18:18:54.015069 12922 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0413 18:18:54.015084 12922 net.cpp:150] Setting up relu4_3
I0413 18:18:54.015094 12922 net.cpp:157] Top shape: 1 512 125 188 (12032000)
I0413 18:18:54.015100 12922 net.cpp:165] Memory required for data: 3390832116
I0413 18:18:54.015106 12922 layer_factory.hpp:77] Creating layer pool4
I0413 18:18:54.015116 12922 net.cpp:100] Creating Layer pool4
I0413 18:18:54.015123 12922 net.cpp:434] pool4 <- conv4_3
I0413 18:18:54.015135 12922 net.cpp:408] pool4 -> pool4
I0413 18:18:54.015183 12922 net.cpp:150] Setting up pool4
I0413 18:18:54.015194 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.015200 12922 net.cpp:165] Memory required for data: 3402960372
I0413 18:18:54.015206 12922 layer_factory.hpp:77] Creating layer conv5_1
I0413 18:18:54.015223 12922 net.cpp:100] Creating Layer conv5_1
I0413 18:18:54.015231 12922 net.cpp:434] conv5_1 <- pool4
I0413 18:18:54.015245 12922 net.cpp:408] conv5_1 -> conv5_1
I0413 18:18:54.020321 12922 net.cpp:150] Setting up conv5_1
I0413 18:18:54.020366 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.020373 12922 net.cpp:165] Memory required for data: 3415088628
I0413 18:18:54.020390 12922 layer_factory.hpp:77] Creating layer relu5_1
I0413 18:18:54.020404 12922 net.cpp:100] Creating Layer relu5_1
I0413 18:18:54.020412 12922 net.cpp:434] relu5_1 <- conv5_1
I0413 18:18:54.020426 12922 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0413 18:18:54.020450 12922 net.cpp:150] Setting up relu5_1
I0413 18:18:54.020462 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.020468 12922 net.cpp:165] Memory required for data: 3427216884
I0413 18:18:54.020474 12922 layer_factory.hpp:77] Creating layer conv5_2
I0413 18:18:54.020488 12922 net.cpp:100] Creating Layer conv5_2
I0413 18:18:54.020494 12922 net.cpp:434] conv5_2 <- conv5_1
I0413 18:18:54.020508 12922 net.cpp:408] conv5_2 -> conv5_2
I0413 18:18:54.025682 12922 net.cpp:150] Setting up conv5_2
I0413 18:18:54.025717 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.025729 12922 net.cpp:165] Memory required for data: 3439345140
I0413 18:18:54.025740 12922 layer_factory.hpp:77] Creating layer relu5_2
I0413 18:18:54.025751 12922 net.cpp:100] Creating Layer relu5_2
I0413 18:18:54.025758 12922 net.cpp:434] relu5_2 <- conv5_2
I0413 18:18:54.025768 12922 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0413 18:18:54.025784 12922 net.cpp:150] Setting up relu5_2
I0413 18:18:54.025794 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.025799 12922 net.cpp:165] Memory required for data: 3451473396
I0413 18:18:54.025804 12922 layer_factory.hpp:77] Creating layer conv5_3
I0413 18:18:54.025825 12922 net.cpp:100] Creating Layer conv5_3
I0413 18:18:54.025859 12922 net.cpp:434] conv5_3 <- conv5_2
I0413 18:18:54.025890 12922 net.cpp:408] conv5_3 -> conv5_3
I0413 18:18:54.030344 12922 net.cpp:150] Setting up conv5_3
I0413 18:18:54.030382 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.030386 12922 net.cpp:165] Memory required for data: 3463601652
I0413 18:18:54.030396 12922 layer_factory.hpp:77] Creating layer relu5_3
I0413 18:18:54.030407 12922 net.cpp:100] Creating Layer relu5_3
I0413 18:18:54.030412 12922 net.cpp:434] relu5_3 <- conv5_3
I0413 18:18:54.030421 12922 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0413 18:18:54.030432 12922 net.cpp:150] Setting up relu5_3
I0413 18:18:54.030449 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.030452 12922 net.cpp:165] Memory required for data: 3475729908
I0413 18:18:54.030457 12922 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0413 18:18:54.030462 12922 net.cpp:100] Creating Layer conv5_3_relu5_3_0_split
I0413 18:18:54.030465 12922 net.cpp:434] conv5_3_relu5_3_0_split <- conv5_3
I0413 18:18:54.030472 12922 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0413 18:18:54.030480 12922 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0413 18:18:54.030515 12922 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0413 18:18:54.030524 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.030527 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.030530 12922 net.cpp:165] Memory required for data: 3499986420
I0413 18:18:54.030534 12922 layer_factory.hpp:77] Creating layer rpn_big_conv1
I0413 18:18:54.030547 12922 net.cpp:100] Creating Layer rpn_big_conv1
I0413 18:18:54.030552 12922 net.cpp:434] rpn_big_conv1 <- conv5_3_relu5_3_0_split_0
I0413 18:18:54.030558 12922 net.cpp:408] rpn_big_conv1 -> rpn_big_conv1
I0413 18:18:54.057075 12922 net.cpp:150] Setting up rpn_big_conv1
I0413 18:18:54.057106 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.057119 12922 net.cpp:165] Memory required for data: 3512114676
I0413 18:18:54.057130 12922 layer_factory.hpp:77] Creating layer rpn_big_conv1_relu
I0413 18:18:54.057142 12922 net.cpp:100] Creating Layer rpn_big_conv1_relu
I0413 18:18:54.057147 12922 net.cpp:434] rpn_big_conv1_relu <- rpn_big_conv1
I0413 18:18:54.057154 12922 net.cpp:395] rpn_big_conv1_relu -> rpn_big_conv1 (in-place)
I0413 18:18:54.057164 12922 net.cpp:150] Setting up rpn_big_conv1_relu
I0413 18:18:54.057169 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.057173 12922 net.cpp:165] Memory required for data: 3524242932
I0413 18:18:54.057175 12922 layer_factory.hpp:77] Creating layer rpn_big_conv2
I0413 18:18:54.057188 12922 net.cpp:100] Creating Layer rpn_big_conv2
I0413 18:18:54.057204 12922 net.cpp:434] rpn_big_conv2 <- rpn_big_conv1
I0413 18:18:54.057210 12922 net.cpp:408] rpn_big_conv2 -> rpn_big_conv2
I0413 18:18:54.083319 12922 net.cpp:150] Setting up rpn_big_conv2
I0413 18:18:54.083351 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.083355 12922 net.cpp:165] Memory required for data: 3536371188
I0413 18:18:54.083365 12922 layer_factory.hpp:77] Creating layer rpn_big_conv2_relu
I0413 18:18:54.083377 12922 net.cpp:100] Creating Layer rpn_big_conv2_relu
I0413 18:18:54.083382 12922 net.cpp:434] rpn_big_conv2_relu <- rpn_big_conv2
I0413 18:18:54.083389 12922 net.cpp:395] rpn_big_conv2_relu -> rpn_big_conv2 (in-place)
I0413 18:18:54.083402 12922 net.cpp:150] Setting up rpn_big_conv2_relu
I0413 18:18:54.083408 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.083411 12922 net.cpp:165] Memory required for data: 3548499444
I0413 18:18:54.083415 12922 layer_factory.hpp:77] Creating layer rpn_big_conv2_drop
I0413 18:18:54.083422 12922 net.cpp:100] Creating Layer rpn_big_conv2_drop
I0413 18:18:54.083426 12922 net.cpp:434] rpn_big_conv2_drop <- rpn_big_conv2
I0413 18:18:54.083431 12922 net.cpp:395] rpn_big_conv2_drop -> rpn_big_conv2 (in-place)
I0413 18:18:54.083456 12922 net.cpp:150] Setting up rpn_big_conv2_drop
I0413 18:18:54.083462 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.083465 12922 net.cpp:165] Memory required for data: 3560627700
I0413 18:18:54.083468 12922 layer_factory.hpp:77] Creating layer rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 18:18:54.083473 12922 net.cpp:100] Creating Layer rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 18:18:54.083477 12922 net.cpp:434] rpn_big_conv2_rpn_big_conv2_drop_0_split <- rpn_big_conv2
I0413 18:18:54.083483 12922 net.cpp:408] rpn_big_conv2_rpn_big_conv2_drop_0_split -> rpn_big_conv2_rpn_big_conv2_drop_0_split_0
I0413 18:18:54.083490 12922 net.cpp:408] rpn_big_conv2_rpn_big_conv2_drop_0_split -> rpn_big_conv2_rpn_big_conv2_drop_0_split_1
I0413 18:18:54.083528 12922 net.cpp:150] Setting up rpn_big_conv2_rpn_big_conv2_drop_0_split
I0413 18:18:54.083536 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.083540 12922 net.cpp:157] Top shape: 1 512 63 94 (3032064)
I0413 18:18:54.083544 12922 net.cpp:165] Memory required for data: 3584884212
I0413 18:18:54.083546 12922 layer_factory.hpp:77] Creating layer rpn_big_output_cls
I0413 18:18:54.083564 12922 net.cpp:100] Creating Layer rpn_big_output_cls
I0413 18:18:54.083569 12922 net.cpp:434] rpn_big_output_cls <- rpn_big_conv2_rpn_big_conv2_drop_0_split_0
I0413 18:18:54.083575 12922 net.cpp:408] rpn_big_output_cls -> rpn_big_output_cls
I0413 18:18:54.106165 12922 net.cpp:150] Setting up rpn_big_output_cls
I0413 18:18:54.106194 12922 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 18:18:54.106207 12922 net.cpp:165] Memory required for data: 3593980404
I0413 18:18:54.106218 12922 layer_factory.hpp:77] Creating layer rpn_big_output_cls_relu
I0413 18:18:54.106228 12922 net.cpp:100] Creating Layer rpn_big_output_cls_relu
I0413 18:18:54.106233 12922 net.cpp:434] rpn_big_output_cls_relu <- rpn_big_output_cls
I0413 18:18:54.106247 12922 net.cpp:395] rpn_big_output_cls_relu -> rpn_big_output_cls (in-place)
I0413 18:18:54.106262 12922 net.cpp:150] Setting up rpn_big_output_cls_relu
I0413 18:18:54.106272 12922 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 18:18:54.106278 12922 net.cpp:165] Memory required for data: 3603076596
I0413 18:18:54.106283 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_score
I0413 18:18:54.106300 12922 net.cpp:100] Creating Layer rpn_big_cls_score
I0413 18:18:54.106307 12922 net.cpp:434] rpn_big_cls_score <- rpn_big_output_cls
I0413 18:18:54.106319 12922 net.cpp:408] rpn_big_cls_score -> rpn_big_cls_score
I0413 18:18:54.111104 12922 net.cpp:150] Setting up rpn_big_cls_score
I0413 18:18:54.111129 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111140 12922 net.cpp:165] Memory required for data: 3604243892
I0413 18:18:54.111160 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 18:18:54.111169 12922 net.cpp:100] Creating Layer rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 18:18:54.111176 12922 net.cpp:434] rpn_big_cls_score_rpn_big_cls_score_0_split <- rpn_big_cls_score
I0413 18:18:54.111188 12922 net.cpp:408] rpn_big_cls_score_rpn_big_cls_score_0_split -> rpn_big_cls_score_rpn_big_cls_score_0_split_0
I0413 18:18:54.111202 12922 net.cpp:408] rpn_big_cls_score_rpn_big_cls_score_0_split -> rpn_big_cls_score_rpn_big_cls_score_0_split_1
I0413 18:18:54.111260 12922 net.cpp:150] Setting up rpn_big_cls_score_rpn_big_cls_score_0_split
I0413 18:18:54.111274 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111287 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111292 12922 net.cpp:165] Memory required for data: 3606578484
I0413 18:18:54.111299 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_score_reshape
I0413 18:18:54.111311 12922 net.cpp:100] Creating Layer rpn_big_cls_score_reshape
I0413 18:18:54.111317 12922 net.cpp:434] rpn_big_cls_score_reshape <- rpn_big_cls_score_rpn_big_cls_score_0_split_0
I0413 18:18:54.111326 12922 net.cpp:408] rpn_big_cls_score_reshape -> rpn_big_cls_score_reshape
I0413 18:18:54.111361 12922 net.cpp:150] Setting up rpn_big_cls_score_reshape
I0413 18:18:54.111373 12922 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 18:18:54.111379 12922 net.cpp:165] Memory required for data: 3607745780
I0413 18:18:54.111385 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 18:18:54.111394 12922 net.cpp:100] Creating Layer rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 18:18:54.111402 12922 net.cpp:434] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split <- rpn_big_cls_score_reshape
I0413 18:18:54.111408 12922 net.cpp:408] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split -> rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_0
I0413 18:18:54.111423 12922 net.cpp:408] rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split -> rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_1
I0413 18:18:54.111469 12922 net.cpp:150] Setting up rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split
I0413 18:18:54.111480 12922 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 18:18:54.111488 12922 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 18:18:54.111493 12922 net.cpp:165] Memory required for data: 3610080372
I0413 18:18:54.111498 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_prob
I0413 18:18:54.111510 12922 net.cpp:100] Creating Layer rpn_big_cls_prob
I0413 18:18:54.111515 12922 net.cpp:434] rpn_big_cls_prob <- rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_0
I0413 18:18:54.111523 12922 net.cpp:408] rpn_big_cls_prob -> rpn_big_cls_prob
I0413 18:18:54.111601 12922 net.cpp:150] Setting up rpn_big_cls_prob
I0413 18:18:54.111613 12922 net.cpp:157] Top shape: 1 2 1586 92 (291824)
I0413 18:18:54.111619 12922 net.cpp:165] Memory required for data: 3611247668
I0413 18:18:54.111624 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_prob_reshape
I0413 18:18:54.111632 12922 net.cpp:100] Creating Layer rpn_big_cls_prob_reshape
I0413 18:18:54.111639 12922 net.cpp:434] rpn_big_cls_prob_reshape <- rpn_big_cls_prob
I0413 18:18:54.111649 12922 net.cpp:408] rpn_big_cls_prob_reshape -> rpn_big_cls_prob_reshape
I0413 18:18:54.111680 12922 net.cpp:150] Setting up rpn_big_cls_prob_reshape
I0413 18:18:54.111691 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111697 12922 net.cpp:165] Memory required for data: 3612414964
I0413 18:18:54.111702 12922 layer_factory.hpp:77] Creating layer rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 18:18:54.111711 12922 net.cpp:100] Creating Layer rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 18:18:54.111717 12922 net.cpp:434] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split <- rpn_big_cls_prob_reshape
I0413 18:18:54.111727 12922 net.cpp:408] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split -> rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_0
I0413 18:18:54.111738 12922 net.cpp:408] rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split -> rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_1
I0413 18:18:54.111783 12922 net.cpp:150] Setting up rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split
I0413 18:18:54.111793 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111801 12922 net.cpp:157] Top shape: 1 52 61 92 (291824)
I0413 18:18:54.111807 12922 net.cpp:165] Memory required for data: 3614749556
I0413 18:18:54.111814 12922 layer_factory.hpp:77] Creating layer rpn_big_anchor_target
I0413 18:18:54.113353 12922 net.cpp:100] Creating Layer rpn_big_anchor_target
I0413 18:18:54.113368 12922 net.cpp:434] rpn_big_anchor_target <- rpn_big_cls_score_rpn_big_cls_score_0_split_1
I0413 18:18:54.113376 12922 net.cpp:434] rpn_big_anchor_target <- input_gt_boxes_input_2_split_0
I0413 18:18:54.113384 12922 net.cpp:434] rpn_big_anchor_target <- input_ignored_boxes
I0413 18:18:54.113394 12922 net.cpp:434] rpn_big_anchor_target <- input_im_info_input_1_split_0
I0413 18:18:54.113402 12922 net.cpp:434] rpn_big_anchor_target <- input_data_input_0_split_1
I0413 18:18:54.113410 12922 net.cpp:434] rpn_big_anchor_target <- rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_0
I0413 18:18:54.113422 12922 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_labels
I0413 18:18:54.113437 12922 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_bbox_targets
I0413 18:18:54.113452 12922 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_inside_weights
I0413 18:18:54.113467 12922 net.cpp:408] rpn_big_anchor_target -> rpn_big_anchor_target_outside_weights
I0413 18:18:54.118468 12922 net.cpp:150] Setting up rpn_big_anchor_target
I0413 18:18:54.118492 12922 net.cpp:157] Top shape: 1 1 1586 92 (145912)
I0413 18:18:54.118506 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.118510 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.118515 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.118517 12922 net.cpp:165] Memory required for data: 3622336980
I0413 18:18:54.118523 12922 layer_factory.hpp:77] Creating layer rpn_big_loss_cls
I0413 18:18:54.118533 12922 net.cpp:100] Creating Layer rpn_big_loss_cls
I0413 18:18:54.118541 12922 net.cpp:434] rpn_big_loss_cls <- rpn_big_cls_score_reshape_rpn_big_cls_score_reshape_0_split_1
I0413 18:18:54.118551 12922 net.cpp:434] rpn_big_loss_cls <- rpn_big_anchor_target_labels
I0413 18:18:54.118561 12922 net.cpp:408] rpn_big_loss_cls -> rpn_big_loss_cls
I0413 18:18:54.118577 12922 layer_factory.hpp:77] Creating layer rpn_big_loss_cls
I0413 18:18:54.119400 12922 net.cpp:150] Setting up rpn_big_loss_cls
I0413 18:18:54.119426 12922 net.cpp:157] Top shape: (1)
I0413 18:18:54.119431 12922 net.cpp:160]     with loss weight 1
I0413 18:18:54.119446 12922 net.cpp:165] Memory required for data: 3622336984
I0413 18:18:54.119473 12922 layer_factory.hpp:77] Creating layer rpn_big_output_box
I0413 18:18:54.119506 12922 net.cpp:100] Creating Layer rpn_big_output_box
I0413 18:18:54.119515 12922 net.cpp:434] rpn_big_output_box <- rpn_big_conv2_rpn_big_conv2_drop_0_split_1
I0413 18:18:54.119532 12922 net.cpp:408] rpn_big_output_box -> rpn_big_output_box
I0413 18:18:54.138599 12922 net.cpp:150] Setting up rpn_big_output_box
I0413 18:18:54.138643 12922 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 18:18:54.138650 12922 net.cpp:165] Memory required for data: 3631433176
I0413 18:18:54.138665 12922 layer_factory.hpp:77] Creating layer rpn_big_output_box_relu
I0413 18:18:54.138684 12922 net.cpp:100] Creating Layer rpn_big_output_box_relu
I0413 18:18:54.138694 12922 net.cpp:434] rpn_big_output_box_relu <- rpn_big_output_box
I0413 18:18:54.138707 12922 net.cpp:395] rpn_big_output_box_relu -> rpn_big_output_box (in-place)
I0413 18:18:54.138727 12922 net.cpp:150] Setting up rpn_big_output_box_relu
I0413 18:18:54.138741 12922 net.cpp:157] Top shape: 1 384 63 94 (2274048)
I0413 18:18:54.138756 12922 net.cpp:165] Memory required for data: 3640529368
I0413 18:18:54.138763 12922 layer_factory.hpp:77] Creating layer rpn_big_bbox_pred
I0413 18:18:54.138778 12922 net.cpp:100] Creating Layer rpn_big_bbox_pred
I0413 18:18:54.138784 12922 net.cpp:434] rpn_big_bbox_pred <- rpn_big_output_box
I0413 18:18:54.138797 12922 net.cpp:408] rpn_big_bbox_pred -> rpn_big_bbox_pred
I0413 18:18:54.143657 12922 net.cpp:150] Setting up rpn_big_bbox_pred
I0413 18:18:54.143689 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.143693 12922 net.cpp:165] Memory required for data: 3642863960
I0413 18:18:54.143703 12922 layer_factory.hpp:77] Creating layer rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 18:18:54.143713 12922 net.cpp:100] Creating Layer rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 18:18:54.143718 12922 net.cpp:434] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split <- rpn_big_bbox_pred
I0413 18:18:54.143728 12922 net.cpp:408] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split -> rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_0
I0413 18:18:54.143738 12922 net.cpp:408] rpn_big_bbox_pred_rpn_big_bbox_pred_0_split -> rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_1
I0413 18:18:54.143774 12922 net.cpp:150] Setting up rpn_big_bbox_pred_rpn_big_bbox_pred_0_split
I0413 18:18:54.143786 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.143795 12922 net.cpp:157] Top shape: 1 104 61 92 (583648)
I0413 18:18:54.143800 12922 net.cpp:165] Memory required for data: 3647533144
I0413 18:18:54.143805 12922 layer_factory.hpp:77] Creating layer rpn_big_loss_bbox
I0413 18:18:54.144168 12922 net.cpp:100] Creating Layer rpn_big_loss_bbox
I0413 18:18:54.144179 12922 net.cpp:434] rpn_big_loss_bbox <- rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_0
I0413 18:18:54.144188 12922 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_bbox_targets
I0413 18:18:54.144196 12922 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_inside_weights
I0413 18:18:54.144204 12922 net.cpp:434] rpn_big_loss_bbox <- rpn_big_anchor_target_outside_weights
I0413 18:18:54.144217 12922 net.cpp:408] rpn_big_loss_bbox -> rpn_big_loss_bbox
I0413 18:18:54.146268 12922 net.cpp:150] Setting up rpn_big_loss_bbox
I0413 18:18:54.146306 12922 net.cpp:157] Top shape: 1 (1)
I0413 18:18:54.146311 12922 net.cpp:160]     with loss weight 1
I0413 18:18:54.146327 12922 net.cpp:165] Memory required for data: 3647533148
I0413 18:18:54.146337 12922 layer_factory.hpp:77] Creating layer proposal
I0413 18:18:54.146806 12922 net.cpp:100] Creating Layer proposal
I0413 18:18:54.146824 12922 net.cpp:434] proposal <- rpn_big_cls_prob_reshape_rpn_big_cls_prob_reshape_0_split_1
I0413 18:18:54.146834 12922 net.cpp:434] proposal <- rpn_big_bbox_pred_rpn_big_bbox_pred_0_split_1
I0413 18:18:54.146842 12922 net.cpp:434] proposal <- input_im_info_input_1_split_1
I0413 18:18:54.146852 12922 net.cpp:408] proposal -> rpn_rois
I0413 18:18:54.151252 12922 net.cpp:150] Setting up proposal
I0413 18:18:54.151270 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:54.151273 12922 net.cpp:165] Memory required for data: 3647533168
I0413 18:18:54.151288 12922 layer_factory.hpp:77] Creating layer roi-data
I0413 18:18:54.151624 12922 net.cpp:100] Creating Layer roi-data
I0413 18:18:54.151633 12922 net.cpp:434] roi-data <- rpn_rois
I0413 18:18:54.151640 12922 net.cpp:434] roi-data <- input_gt_boxes_input_2_split_1
I0413 18:18:54.151656 12922 net.cpp:408] roi-data -> rois
I0413 18:18:54.151665 12922 net.cpp:408] roi-data -> labels
I0413 18:18:54.151672 12922 net.cpp:408] roi-data -> bbox_targets
I0413 18:18:54.151679 12922 net.cpp:408] roi-data -> bbox_inside_weights
I0413 18:18:54.151685 12922 net.cpp:408] roi-data -> bbox_outside_weights
I0413 18:18:54.151692 12922 net.cpp:408] roi-data -> pid_label
I0413 18:18:54.152619 12922 net.cpp:150] Setting up roi-data
I0413 18:18:54.152631 12922 net.cpp:157] Top shape: 1 5 (5)
I0413 18:18:54.152636 12922 net.cpp:157] Top shape: 1 1 (1)
I0413 18:18:54.152647 12922 net.cpp:157] Top shape: 1 8 (8)
I0413 18:18:54.152652 12922 net.cpp:157] Top shape: 1 8 (8)
I0413 18:18:54.152654 12922 net.cpp:157] Top shape: 1 8 (8)
I0413 18:18:54.152658 12922 net.cpp:157] Top shape: (0)
I0413 18:18:54.152662 12922 net.cpp:165] Memory required for data: 3647533288
I0413 18:18:54.152665 12922 layer_factory.hpp:77] Creating layer roi-pool
I0413 18:18:54.152673 12922 net.cpp:100] Creating Layer roi-pool
I0413 18:18:54.152678 12922 net.cpp:434] roi-pool <- conv5_3_relu5_3_0_split_1
I0413 18:18:54.152681 12922 net.cpp:434] roi-pool <- rois
I0413 18:18:54.152688 12922 net.cpp:408] roi-pool -> roi-pool
I0413 18:18:54.152696 12922 roi_pooling_layer.cpp:33] Spatial scale: 0.0625
I0413 18:18:54.152709 12922 roi_pooling_layer.cpp:34] Box scale: 1
I0413 18:18:54.152747 12922 net.cpp:150] Setting up roi-pool
I0413 18:18:54.152755 12922 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0413 18:18:54.152758 12922 net.cpp:165] Memory required for data: 3647633640
I0413 18:18:54.152762 12922 layer_factory.hpp:77] Creating layer fc6
I0413 18:18:54.152770 12922 net.cpp:100] Creating Layer fc6
I0413 18:18:54.152775 12922 net.cpp:434] fc6 <- roi-pool
I0413 18:18:54.152779 12922 net.cpp:408] fc6 -> fc6
I0413 18:18:54.315892 12922 net.cpp:150] Setting up fc6
I0413 18:18:54.315928 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.315940 12922 net.cpp:165] Memory required for data: 3647650024
I0413 18:18:54.315953 12922 layer_factory.hpp:77] Creating layer relu6
I0413 18:18:54.315963 12922 net.cpp:100] Creating Layer relu6
I0413 18:18:54.315968 12922 net.cpp:434] relu6 <- fc6
I0413 18:18:54.315978 12922 net.cpp:395] relu6 -> fc6 (in-place)
I0413 18:18:54.315989 12922 net.cpp:150] Setting up relu6
I0413 18:18:54.315992 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.315995 12922 net.cpp:165] Memory required for data: 3647666408
I0413 18:18:54.315999 12922 layer_factory.hpp:77] Creating layer drop6
I0413 18:18:54.316005 12922 net.cpp:100] Creating Layer drop6
I0413 18:18:54.316009 12922 net.cpp:434] drop6 <- fc6
I0413 18:18:54.316014 12922 net.cpp:395] drop6 -> fc6 (in-place)
I0413 18:18:54.316035 12922 net.cpp:150] Setting up drop6
I0413 18:18:54.316045 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.316049 12922 net.cpp:165] Memory required for data: 3647682792
I0413 18:18:54.316054 12922 layer_factory.hpp:77] Creating layer fc7
I0413 18:18:54.316067 12922 net.cpp:100] Creating Layer fc7
I0413 18:18:54.316082 12922 net.cpp:434] fc7 <- fc6
I0413 18:18:54.316092 12922 net.cpp:408] fc7 -> fc7
I0413 18:18:54.342942 12922 net.cpp:150] Setting up fc7
I0413 18:18:54.342983 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.342988 12922 net.cpp:165] Memory required for data: 3647699176
I0413 18:18:54.343010 12922 layer_factory.hpp:77] Creating layer relu7
I0413 18:18:54.343041 12922 net.cpp:100] Creating Layer relu7
I0413 18:18:54.343051 12922 net.cpp:434] relu7 <- fc7
I0413 18:18:54.343062 12922 net.cpp:395] relu7 -> fc7 (in-place)
I0413 18:18:54.343078 12922 net.cpp:150] Setting up relu7
I0413 18:18:54.343089 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.343094 12922 net.cpp:165] Memory required for data: 3647715560
I0413 18:18:54.343102 12922 layer_factory.hpp:77] Creating layer drop7
I0413 18:18:54.343113 12922 net.cpp:100] Creating Layer drop7
I0413 18:18:54.343122 12922 net.cpp:434] drop7 <- fc7
I0413 18:18:54.343133 12922 net.cpp:395] drop7 -> fc7 (in-place)
I0413 18:18:54.343165 12922 net.cpp:150] Setting up drop7
I0413 18:18:54.343174 12922 net.cpp:157] Top shape: 1 4096 (4096)
I0413 18:18:54.343180 12922 net.cpp:165] Memory required for data: 3647731944
I0413 18:18:54.343186 12922 layer_factory.hpp:77] Creating layer bbox_pred
I0413 18:18:54.343197 12922 net.cpp:100] Creating Layer bbox_pred
I0413 18:18:54.343205 12922 net.cpp:434] bbox_pred <- fc7
I0413 18:18:54.343215 12922 net.cpp:408] bbox_pred -> bbox_pred
F0413 18:18:54.343258 12922 blob.cpp:186] Check failed: data_ 
*** Check failure stack trace: ***
exps/train_model.sh: line 26: 12922 Aborted                 (core dumped) python3 ./tools/train_net.py --gpu 0 --cfg exps/${EXP_NAME}/config.yml --exp_dir ${EXP_NAME} ${EXTRA_ARGS}
